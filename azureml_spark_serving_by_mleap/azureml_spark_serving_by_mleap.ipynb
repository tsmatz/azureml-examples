{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark ML serving with MLeap in Azure Machine Learning\n",
    "\n",
    "In this notebook, we'll host Spark ML serving (online prediction) by using MLeap.\n",
    "\n",
    "Spark ML pipeline model (which is trained on Apache Spark) can be converted into MLeap format (MLeap bundle). Using MLeap format, you can then serve Spark MLlib model on a lightweight single container without Apache Spark installation.\n",
    "\n",
    "> Note : I note that you cannot always take this method, because not all model in Spark can be serialized into MLeap. (such as, LightGBM model built with SynapseML library)\n",
    "\n",
    "To run this notebook,\n",
    "\n",
    "1. Create new \"Machine Learning\" resource in [Azure Portal](https://portal.azure.com/).\n",
    "2. Install Azure Machine Learning CLI v2 on Ubuntu as follows\n",
    "\n",
    "```\n",
    "# install Azure CLI\n",
    "curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n",
    "# install AML CLI extension\n",
    "az extension add --name ml\n",
    "```\n",
    "\n",
    "> Note : See [here](https://tsmatz.wordpress.com/2019/03/04/spark-ml-pipeline-serving-inference-by-azure-machine-learning-service/) for other deployment options for Spark ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Azure Machine Learning workspace\n",
    "\n",
    "Login to Azure and prepare for connecting to Azure Machine Learning (AML) workspace.<br>\n",
    "Please fill the following subscription id, AML workspace name, and resource group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s {AZURE_SUBSCRIPTION_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resource_group = \"{AML_RESOURCE_GROUP_NAME}\"\n",
    "my_workspace = \"{AML_WORSPACE_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and convert to MLeap format\n",
    "\n",
    "First train Spark ML pipeline on Apache Spark, and convert model into MLeap bundle (.zip file).\n",
    "\n",
    "In this example, we use MLeap pipeline bundle, ```flight-delay-classify.zip```, which is trained in [this Databricks exercise](https://tsmatz.github.io/azure-databricks-exercise/exercise05-mleap.html).<br>\n",
    "This pipeline uses inputs for flight and weather information (such as, aircraft carrier, depature/arrival time, depature/arrival wind speed, depature/arrival visibility, etc) and then predicts flight arrival's delay over 15 minutes by 0 or 1.\n",
    "\n",
    "Now we register this trained MLeap bundle into Azure Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading flight-delay-classify.zip\u001b[32m (< 1 MB): 100%|â–ˆ| 165k/165k [00:00<00:00, 2.\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-08-29T00:44:48.804476+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2022-08-29T00:44:48.804476+00:00\",\n",
      "    \"last_modified_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/models/fight_delay_mleap_model/versions/1\",\n",
      "  \"name\": \"fight_delay_mleap_model\",\n",
      "  \"path\": \"azureml://subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/workspaces/ws01/datastores/workspaceblobstore/paths/LocalUpload/7c2e0fe6bee0b71f677559eeb284167c/flight-delay-classify.zip\",\n",
      "  \"properties\": {},\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"custom_model\",\n",
      "  \"version\": \"1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml model create --name fight_delay_mleap_model \\\n",
    "  --version 1 \\\n",
    "  --path ./flight-delay-classify.zip \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a managed endpoint\n",
    "\n",
    "Now create a managed endpoint. **Fill the following endpoint name**, which must be unique in DNS.\n",
    "\n",
    "Afterwards, we will deploy inferencing container image on this endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing managed_endpoint.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile managed_endpoint.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineEndpoint.schema.json\n",
    "name: {FILL_UNIQUE_ENDPOINT_NAME}\n",
    "auth_mode: key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"auth_mode\": \"key\",\n",
      "  \"id\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/onlineEndpoints/aml-mleap-test01\",\n",
      "  \"identity\": {\n",
      "    \"principal_id\": \"db05a1d4-d34c-44f9-b77e-ccc9e09d22fd\",\n",
      "    \"tenant_id\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "    \"type\": \"system_assigned\"\n",
      "  },\n",
      "  \"kind\": \"Managed\",\n",
      "  \"location\": \"eastus\",\n",
      "  \"mirror_traffic\": {},\n",
      "  \"name\": \"aml-mleap-test01\",\n",
      "  \"properties\": {\n",
      "    \"AzureAsyncOperationUri\": \"https://management.azure.com/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oe:b08a1272-2af0-4e5c-bcdf-bb474ba3c272:7f419933-3dc5-4ca2-b76f-dc9b7b1666d1?api-version=2022-02-01-preview\",\n",
      "    \"azureml.onlineendpointid\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/aml-rg/providers/microsoft.machinelearningservices/workspaces/ws01/onlineendpoints/aml-mleap-test01\"\n",
      "  },\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"public_network_access\": \"enabled\",\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"scoring_uri\": \"https://aml-mleap-test01.eastus.inference.ml.azure.com/score\",\n",
      "  \"swagger_uri\": \"https://aml-mleap-test01.eastus.inference.ml.azure.com/swagger.json\",\n",
      "  \"tags\": {},\n",
      "  \"traffic\": {}\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint create --file managed_endpoint.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy inferencing with MLeap runtime\n",
    "\n",
    "Now we deploy inferencing image on this endpoint.\n",
    "\n",
    "In this example, we use the following pre-built MLeap serving container image with Spring Boot framework.\n",
    "\n",
    "MLeap Serving (Spring Boot) :<br>\n",
    "[https://combust.github.io/mleap-docs/mleap-serving/](https://combust.github.io/mleap-docs/mleap-serving/)\n",
    "\n",
    "In the following settings :\n",
    "- The model (which is registered above) is mounted as ```/models```. This directory is used in model loading later.\n",
    "- The port number 65327 is default port for MLeap Spring Boot Serving. (See [here](https://combust.github.io/mleap-docs/mleap-serving/).)<br>\n",
    "  The url ```http://localhost:65327/actuator``` is then used for liveness endpoint.\n",
    "- The endpoint ```http://localhost:65327/``` is exposed by ```https://{ENDPOINT ADDRESS}/``` and ```https://{ENDPOINT ADDRESS}/models``` is returned as scoring url by the following ```environment/inference_config/scoring_route``` setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing managed_deployment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile managed_deployment.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json\n",
    "name: flight-delay-deployment\n",
    "endpoint_name: {FILL_UNIQUE_ENDPOINT_NAME}\n",
    "model: azureml:fight_delay_mleap_model@latest\n",
    "model_mount_path: /models\n",
    "environment:\n",
    "  image: docker.io/combustml/mleap-spring-boot:0.21.0-SNAPSHOT\n",
    "  inference_config:\n",
    "    liveness_route:\n",
    "      port: 65327\n",
    "      path: /actuator\n",
    "    readiness_route:\n",
    "      port: 65327\n",
    "      path: /actuator\n",
    "    scoring_route:\n",
    "      port: 65327\n",
    "      path: /models\n",
    "instance_type: Standard_DS2_v2\n",
    "instance_count: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All traffic will be set to deployment flight-delay-deployment once it has been provisioned.\n",
      "If you interrupt this command or it times out while waiting for the provisioning, you can try to set all the traffic to this deployment later once its has been provisioned.\n",
      "Check: endpoint aml-mleap-test01 exists\n",
      "Creating/updating online deployment flight-delay-deployment .......................................................................Done (6m 17s)\n",
      "{\n",
      "  \"app_insights_enabled\": false,\n",
      "  \"endpoint_name\": \"aml-mleap-test01\",\n",
      "  \"environment\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/environments/CliV2AnonymousEnvironment/versions/4fb6ecfd15e1fc56568a1dd7ba90693e\",\n",
      "  \"environment_variables\": {},\n",
      "  \"instance_count\": 1,\n",
      "  \"instance_type\": \"Standard_DS2_v2\",\n",
      "  \"model\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/models/fight_delay_mleap_model/versions/1\",\n",
      "  \"model_mount_path\": \"/models\",\n",
      "  \"name\": \"flight-delay-deployment\",\n",
      "  \"properties\": {},\n",
      "  \"tags\": {},\n",
      "  \"type\": \"managed\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-deployment create --file managed_deployment.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --all-traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get endpoint url and key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get endpoint url by the following command. (**Fill the following endpoint name**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"{FILL_UNIQUE_ENDPOINT_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"https://aml-mleap-test01.eastus.inference.ml.azure.com/models\"\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint show \\\n",
    "  --name $endpoint_name \\\n",
    "  --query scoring_uri \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get authorization key for this endpoint by the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"primaryKey\": \"0xtXv4OaKnLHBuAqeqGA0vNjs0GPa4Ai\",\r\n",
      "  \"secondaryKey\": \"mqszbFnGi9yrzIzuwbpXwhS8EgJbdR2I\"\r\n",
      "}\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint get-credentials \\\n",
    "  --name $endpoint_name \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test your web service.\n",
    "\n",
    "First, we must load model in ```models/flight-delay-classify.zip``` with the name of ```flight-delay``` as follows.\n",
    "\n",
    "> Note : You can check metadata (such as, schemas in leap frame, etc) of the loaded model by ```GET http://{ENDPOINT_ADDRESS}/models/flight-delay/meta```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = \"{FILL_ENDPOINT_URL}\"\n",
    "# Example : endpoint_url = \"https://aml-mleap-test01.eastus.inference.ml.azure.com/models\"\n",
    "authorization_key = \"{FILL_AUTHORIZATION_KEY}\"\n",
    "# Example : authorization_key = \"0xtXv4OaKnLHBuAqeqGA0vNjs0GPa4Ai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code : 202\n",
      "{'name': 'flight-delay', 'uri': 'file:/models/flight-delay-classify.zip', 'config': {'memoryTimeout': '900000', 'diskTimeout': '900000'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Invoke web service !\n",
    "headers = {\n",
    "    'Content-Type':'application/json',\n",
    "    'Authorization':('Bearer '+ authorization_key)\n",
    "}\n",
    "body = \"{\\\"modelName\\\":\\\"flight-delay\\\",\\\"uri\\\":\\\"file:/models/flight-delay-classify.zip\\\",\\\"config\\\":{\\\"memoryTimeout\\\":900000,\\\"diskTimeout\\\":900000},\\\"force\\\":false}\"\n",
    "http_res = requests.post(\n",
    "    endpoint_url,\n",
    "    body,\n",
    "    headers = headers)\n",
    "\n",
    "# Show results\n",
    "print(\"Status code : {}\".format(http_res.status_code))\n",
    "result_body = json.loads(http_res.text)\n",
    "print(result_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict flight delay with this endpoint as follows. (Call online inferencing.)\n",
    "\n",
    "In the following example, the predicted result is ```0.0``` (which means \"not delayed\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code : 200\n",
      "{'schema': {'fields': [{'name': 'AltimeterOrigin', 'type': 'double'}, {'name': 'RelativeHumidityOrigin', 'type': 'double'}, {'name': 'DryBulbCelsiusDest', 'type': 'double'}, {'name': 'AltimeterDest', 'type': 'double'}, {'name': 'UNIQUE_CARRIER', 'type': 'string'}, {'name': 'ORIGIN', 'type': 'string'}, {'name': 'DewPointCelsiusDest', 'type': 'double'}, {'name': 'DEST', 'type': 'string'}, {'name': 'DAY_OF_WEEK', 'type': 'double'}, {'name': 'MONTH', 'type': 'double'}, {'name': 'RelativeHumidityDest', 'type': 'double'}, {'name': 'CRS_DEP_TIME', 'type': 'double'}, {'name': 'VisibilityDest', 'type': 'double'}, {'name': 'ARR_DEL15', 'type': 'string'}, {'name': 'VisibilityOrigin', 'type': 'double'}, {'name': 'WindSpeedOrigin', 'type': 'double'}, {'name': 'DewPointCelsiusOrigin', 'type': 'double'}, {'name': 'DryBulbCelsiusOrigin', 'type': 'double'}, {'name': 'WindSpeedDest', 'type': 'double'}, {'name': 'CRS_ARR_TIME', 'type': 'double'}, {'name': 'Indexed_UNIQUE_CARRIER', 'type': {'type': 'basic', 'base': 'double', 'isNullable': False}}, {'name': 'Indexed_ORIGIN', 'type': {'type': 'basic', 'base': 'double', 'isNullable': False}}, {'name': 'Indexed_DEST', 'type': {'type': 'basic', 'base': 'double', 'isNullable': False}}, {'name': 'Indexed_ARR_DEL15', 'type': {'type': 'basic', 'base': 'double', 'isNullable': False}}, {'name': 'features', 'type': {'type': 'tensor', 'base': 'double', 'dimensions': [19]}}, {'name': 'rawPrediction', 'type': {'type': 'tensor', 'base': 'double', 'dimensions': [2]}}, {'name': 'probability', 'type': {'type': 'tensor', 'base': 'double', 'dimensions': [2]}}, {'name': 'prediction', 'type': {'type': 'basic', 'base': 'double', 'isNullable': False}}]}, 'rows': [[30.0175, 93.0, 4.5, 30.055, 'DL', 'ATL', 3.95, 'EWR', 1.0, 1.0, 96.5, 8.0, 0.5, '0', 1.0, 7.5, 11.025, 12.05, 6.0, 10.0, 1.0, 0.0, 12.0, 0.0, {'values': [1.0, 1.0, 1.0, 0.0, 12.0, 8.0, 10.0, 93.0, 30.0175, 12.05, 7.5, 1.0, 11.025, 96.5, 30.055, 4.5, 6.0, 0.5, 3.95], 'dimensions': [19]}, {'values': [15.0, 1.0], 'dimensions': [2]}, {'values': [0.9375, 0.0625], 'dimensions': [2]}, 0.0]]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Read leap frame\n",
    "with open('leap-frame.txt') as f:\n",
    "    body = f.read()\n",
    "\n",
    "# Invoke web service !\n",
    "headers = {\n",
    "    'Content-Type':'application/json',\n",
    "    'Authorization':('Bearer '+ authorization_key)\n",
    "}\n",
    "http_res = requests.post(\n",
    "    endpoint_url + \"/flight-delay/transform\",\n",
    "    body,\n",
    "    headers = headers)\n",
    "\n",
    "# Show results\n",
    "# Show results\n",
    "print(\"Status code : {}\".format(http_res.status_code))\n",
    "result_body = json.loads(http_res.text)\n",
    "print(result_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Remove endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml online-endpoint delete \\\n",
    "  --name $endpoint_name \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
