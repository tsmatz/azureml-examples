{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MXNet Distributed Training (MNIST Example) in Azure Machine Learning\n",
    "\n",
    "In this notebook, we run MXNet distributed training in Azure Machine Learning.<br>\n",
    "When the training has completed, the computing instances will automatically be scaled down to 0 instances.\n",
    "To run this notebook,\n",
    "\n",
    "1. Create new \"Machine Learning\" resource in [Azure Portal](https://portal.azure.com/).\n",
    "2. Install Azure Machine Learning CLI v2 on Ubuntu as follows.\n",
    "\n",
    "```\n",
    "# install Azure CLI\n",
    "curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n",
    "# install AML CLI extension\n",
    "az extension add --name ml\n",
    "```\n",
    "\n",
    "See \"[MXNet Distributed Training Example for Azure ML service](https://tsmatz.wordpress.com/2019/01/17/azure-machine-learning-service-custom-amlcompute-and-runconfig-for-mxnet-distributed-training/)\" for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create script for MXNet distributed training (train_mnist.py)\n",
    "\n",
    "Save a script file (```train_mnist.py```) for MXNet distributed training.\n",
    "\n",
    "> Note : Use commented lines on your debugging in local with 1 CPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script-mxnet/train_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train_mnist.py\n",
    "import os, random\n",
    "import argparse\n",
    "import mxnet as mx\n",
    "from mxnet import kv, gluon, autograd, nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "store = kv.create('dist')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--gpus_per_machine\",\n",
    "    type=int,\n",
    "    required=False,\n",
    "    default=1,\n",
    "    help=\"number of gpus in each worker\")\n",
    "parser.add_argument(\"--batch_size_per_gpu\",\n",
    "    type=int,\n",
    "    required=False,\n",
    "    default=64,\n",
    "    help=\"batch size in each gpu\")\n",
    "parser.add_argument(\"--epoch\",\n",
    "    type=int,\n",
    "    required=False,\n",
    "    default=5,\n",
    "    help=\"number of epochs\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "batch_size = args.batch_size_per_gpu * args.gpus_per_machine\n",
    "\n",
    "ctx = [mx.gpu(i) for i in range(args.gpus_per_machine)]\n",
    "# ctx = mx.cpu(0)\n",
    "\n",
    "# for splitting data into wokers\n",
    "class SplitSampler(gluon.data.sampler.Sampler):\n",
    "    \"\"\"\n",
    "    length: Number of examples in the dataset\n",
    "    num_parts: Partition the data into multiple parts\n",
    "    part_index: The index of the part to read from\n",
    "    \"\"\"\n",
    "    def __init__(self, length, num_parts, part_index):\n",
    "        self.part_len = length // num_parts\n",
    "        self.start = self.part_len * part_index\n",
    "        self.end = self.start + self.part_len\n",
    "    def __iter__(self):\n",
    "        indices = list(range(self.start, self.end))\n",
    "        random.shuffle(indices)\n",
    "        return iter(indices)\n",
    "    def __len__(self):\n",
    "        return self.part_len\n",
    "\n",
    "mx.random.seed(42)\n",
    "def data_xform(data):\n",
    "    \"\"\"Move channel axis to the beginning, cast to float32, and normalize to [0, 1]\"\"\"\n",
    "    return nd.moveaxis(data, 2, 0).astype('float32') / 255\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.MNIST(train=True).transform_first(data_xform),\n",
    "    batch_size=batch_size,\n",
    "    sampler=SplitSampler(59904, store.num_workers, store.rank))\n",
    "test_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.MNIST(train=False).transform_first(data_xform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "# train_data = gluon.data.DataLoader(\n",
    "#     gluon.data.vision.MNIST(train=True, root='./data').transform_first(data_xform),\n",
    "#     batch_size=batch_size)\n",
    "# test_data = gluon.data.DataLoader(\n",
    "#     gluon.data.vision.MNIST(train=False, root='./data').transform_first(data_xform),\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False)\n",
    "\n",
    "net = nn.HybridSequential(prefix='MLP_')\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(128, activation='relu'),\n",
    "        nn.Dense(64, activation='relu'),\n",
    "        nn.Dense(10, activation=None)\n",
    "    )\n",
    "\n",
    "net.hybridize()\n",
    "\n",
    "net.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "\n",
    "loss_function = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "trainer = gluon.Trainer(\n",
    "    params=net.collect_params(),\n",
    "    optimizer='sgd',\n",
    "    optimizer_params={'learning_rate': 0.07},\n",
    "    kvstore=store)\n",
    "# trainer = gluon.Trainer(\n",
    "#     params=net.collect_params(),\n",
    "#     optimizer='sgd',\n",
    "#     optimizer_params={'learning_rate': 0.07},\n",
    "# )\n",
    "\n",
    "for epoch in range(args.epoch):\n",
    "    \"\"\" Train ! \"\"\"\n",
    "    for batch in train_data:\n",
    "        inputs = gluon.utils.split_and_load(batch[0], ctx)\n",
    "        labels = gluon.utils.split_and_load(batch[1], ctx)\n",
    "        # inputs = batch[0].as_in_context(ctx)\n",
    "        # labels = batch[1].as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            loss = [loss_function(net(X), Y) for X, Y in zip(inputs, labels)]\n",
    "            # loss = loss_function(net(inputs), labels)\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "        # loss.backward()\n",
    "        trainer.step(batch_size=batch[0].shape[0])\n",
    "    \"\"\" Evaluate and Output ! \"\"\"\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, (test_input, test_label) in enumerate(test_data):\n",
    "        test_input = test_input.as_in_context(ctx[0])\n",
    "        test_label = test_label.as_in_context(ctx[0])\n",
    "        # test_input = test_input.as_in_context(ctx)\n",
    "        # test_label = test_label.as_in_context(ctx)\n",
    "        test_output = net(test_input)\n",
    "        test_pred = nd.argmax(test_output, axis=1)\n",
    "        metric.update(preds=test_pred, labels=test_label)\n",
    "    print('Epoch %d: Accuracy %f' % (epoch, metric.get()[1]))\n",
    "\n",
    "\"\"\" Save Model (both architecture and parameters) \"\"\"\n",
    "if store.rank == 0:\n",
    "    os.makedirs('./outputs', exist_ok=True)\n",
    "    net.export('./outputs/test', epoch=1)\n",
    "# os.makedirs('./outputs', exist_ok=True)\n",
    "# net.export('./outputs/test', epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create shell script for setting up mxnet and running training (run.sh)\n",
    "\n",
    "Create shell script for starting each roles in MXNet distributed training.<br>\n",
    "Here we run the following 4 nodes. (The parameter servers can also be distributed, but here we set 1 parameter server.)\n",
    "\n",
    "- Rank 0 : Scheduler\n",
    "- Rank 1 : Parameter Server\n",
    "- Rank 2 : Worker\n",
    "- Rank 3 : Worker\n",
    "\n",
    "> Note : The following ```$AZ_BATCHAI_MPI_MASTER_NODE``` is an environment variable for MPI master's host name (such as, ```10.5.0.4```).<br>\n",
    "> You can also use the following shell command to retreive master's host name. (See [here](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-distributed-gpu) for environment variables in AML distributed cluster.)<br>\n",
    "> ```cut -d \":\" -f 1 <<< $AZ_BATCH_MASTER_NODE```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script-mxnet/run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/run.sh\n",
    "# setup role\n",
    "if [ $OMPI_COMM_WORLD_RANK -eq 0 ]\n",
    "then\n",
    "    export DMLC_ROLE=scheduler\n",
    "elif [ $OMPI_COMM_WORLD_RANK -eq 1 ]\n",
    "then\n",
    "    export DMLC_ROLE=server\n",
    "else\n",
    "    export DMLC_ROLE=worker\n",
    "fi\n",
    "export DMLC_PS_ROOT_URI=$AZ_BATCHAI_MPI_MASTER_NODE\n",
    "export DMLC_PS_ROOT_PORT=9092\n",
    "export DMLC_NUM_SERVER=1\n",
    "export DMLC_NUM_WORKER=2\n",
    "\n",
    "# run training\n",
    "python train_mnist.py --gpus_per_machine 1 --batch_size_per_gpu 64 --epoch 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submit Job in Azure Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for connecting to Azure Machine Learning workspace\n",
    "\n",
    "Login to Azure and prepare for connecting to Azure Machine Learning (AML) workspace.<br>\n",
    "Please fill the following subscription id, AML workspace name, and resource group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s {AZURE_SUBSCRIPTION_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resource_group = \"{AML_RESOURCE_GROUP_NAME}\"\n",
    "my_workspace = \"{AML_WORSPACE_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cluster (multiple nodes)\n",
    "\n",
    "Create a remote cluster with 4 GPU nodes - 1 head node and 2 worker nodes - scheduler, parameter server, worker 0, and worker 1.\n",
    "\n",
    "For running GPU cluster in Machine Learning, **please check as follows**.\n",
    "\n",
    "- You should have quota for some dedicated ML GPU cluster in your Azure subscription. If you don't have, please request quota in Azure Portal.\n",
    "- Please fill the following ```vm_size``` for GPU VM which you can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/computes/cluster01\",\r\n",
      "  \"idle_time_before_scale_down\": 120,\r\n",
      "  \"location\": \"eastus\",\r\n",
      "  \"max_instances\": 4,\r\n",
      "  \"min_instances\": 0,\r\n",
      "  \"name\": \"cluster01\",\r\n",
      "  \"network_settings\": {},\r\n",
      "  \"provisioning_state\": \"Succeeded\",\r\n",
      "  \"resourceGroup\": \"rg-AML\",\r\n",
      "  \"size\": \"STANDARD_NC6\",\r\n",
      "  \"ssh_public_access_enabled\": true,\r\n",
      "  \"tier\": \"dedicated\",\r\n",
      "  \"type\": \"amlcompute\"\r\n",
      "}\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute create --name cluster01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --type amlcompute \\\n",
    "  --min-instances 0 \\\n",
    "  --max-instances 4 \\\n",
    "  --size Standard_NC4as_T4_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AML environment for MXNet distribution \n",
    "\n",
    "Now we prepare custom environment to run MXNet distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conda_distributed_mxnet.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda_distributed_mxnet.yml\n",
    "name: mxnet_environment\n",
    "dependencies:\n",
    "- python=3.6\n",
    "- pip:\n",
    "  - mxnet-cu90\n",
    "  - mpi4py\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing env_distributed_mxnet.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile env_distributed_mxnet.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json\n",
    "name: mxnet-distribution-env\n",
    "image: tsmatz/azureml-openmpi:0.1.0-gpu\n",
    "conda_file: conda_distributed_mxnet.yml\n",
    "description: environment for mxnet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"conda_file\": {\r\n",
      "    \"channels\": [\r\n",
      "      \"anaconda\",\r\n",
      "      \"conda-forge\"\r\n",
      "    ],\r\n",
      "    \"dependencies\": [\r\n",
      "      \"python=3.6\",\r\n",
      "      {\r\n",
      "        \"pip\": [\r\n",
      "          \"mxnet-cu90\",\r\n",
      "          \"mpi4py\"\r\n",
      "        ]\r\n",
      "      }\r\n",
      "    ],\r\n",
      "    \"name\": \"mxnet_environment\"\r\n",
      "  },\r\n",
      "  \"creation_context\": {\r\n",
      "    \"created_at\": \"2022-08-24T05:54:33.791916+00:00\",\r\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\r\n",
      "    \"created_by_type\": \"User\",\r\n",
      "    \"last_modified_at\": \"2022-08-24T05:54:33.791916+00:00\",\r\n",
      "    \"last_modified_by\": \"Tsuyoshi Matsuzaki\",\r\n",
      "    \"last_modified_by_type\": \"User\"\r\n",
      "  },\r\n",
      "  \"description\": \"environment for mxnet distribution\",\r\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/environments/mxnet-distribution-env/versions/1\",\r\n",
      "  \"image\": \"tsmatz/azureml-openmpi:0.1.0-gpu\",\r\n",
      "  \"name\": \"mxnet-distribution-env\",\r\n",
      "  \"os_type\": \"linux\",\r\n",
      "  \"resourceGroup\": \"rg-AML\",\r\n",
      "  \"tags\": {},\r\n",
      "  \"version\": \"1\"\r\n",
      "}\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml environment create --file env_distributed_mxnet.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Job\n",
    "\n",
    "Now let's run distributed MXNet training.\n",
    "\n",
    "> Note : For the first time to run, it builds new environment and then takes a long time to start training. (Once it's registered, it can speed up to train.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_distributed_mxnet.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_distributed_mxnet.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "code: script\n",
    "command: bash run.sh\n",
    "environment: azureml:mxnet-distribution-env@latest\n",
    "compute: azureml:cluster01\n",
    "display_name: mxnet_dist_test\n",
    "experiment_name: mxnet_dist_test\n",
    "resources:\n",
    "  instance_count: 4\n",
    "distribution:\n",
    "  type: mpi\n",
    "  process_count_per_instance: 1\n",
    "description: MXNet distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading script-mxnet (0.0 MBs): 100%|█| 4631/4631 [00:00<00:00, 154985.13it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"code\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/codes/e545fbff-b6f3-47be-9a21-7ed75cafc161/versions/1\",\n",
      "  \"command\": \"bash run.sh\",\n",
      "  \"compute\": \"azureml:cluster01\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-08-24T05:55:10.280969+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"MXNet distributed training\",\n",
      "  \"display_name\": \"mxnet_dist_test\",\n",
      "  \"distribution\": {\n",
      "    \"process_count_per_instance\": 1,\n",
      "    \"type\": \"mpi\"\n",
      "  },\n",
      "  \"environment\": \"azureml:mxnet-distribution-env:1\",\n",
      "  \"environment_variables\": {},\n",
      "  \"experiment_name\": \"mxnet_dist_test\",\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/goofy_vulture_qc2j57jmx9\",\n",
      "  \"inputs\": {},\n",
      "  \"name\": \"goofy_vulture_qc2j57jmx9\",\n",
      "  \"outputs\": {\n",
      "    \"default\": {\n",
      "      \"mode\": \"rw_mount\",\n",
      "      \"path\": \"azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.goofy_vulture_qc2j57jmx9\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"parameters\": {},\n",
      "  \"properties\": {\n",
      "    \"ContentSnapshotId\": \"0c0eea36-ccfc-4673-b58e-63d35d363163\",\n",
      "    \"_azureml.ComputeTargetType\": \"amlctrain\"\n",
      "  },\n",
      "  \"resourceGroup\": \"rg-AML\",\n",
      "  \"resources\": {\n",
      "    \"instance_count\": 4,\n",
      "    \"properties\": {}\n",
      "  },\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/goofy_vulture_qc2j57jmx9?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/rg-AML/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "      \"job_service_type\": \"Studio\"\n",
      "    },\n",
      "    \"Tracking\": {\n",
      "      \"endpoint\": \"azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01?\",\n",
      "      \"job_service_type\": \"Tracking\"\n",
      "    }\n",
      "  },\n",
      "  \"status\": \"Starting\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"command\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job create --file train_distributed_mxnet.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [Azure Machine Learning studio](https://ml.azure.com/), and see the output's artifacts.<br>\n",
    "The \"```outputs```\" folder includes a generated model, ```outputs/test-0001.params``` and ```outputs/test-symbol.json```, as follows.\n",
    "\n",
    "![output's artifacts](./output_artifact.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the generated model in this training, now you can download result (generated model) in your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"{FILL_JOB_NAME}\"\n",
    "# Example : job_name = \"goofy_vulture_qc2j57jmx9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading artifact azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.goofy_vulture_qc2j57jmx9 to mxnet_training_result/artifacts\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job download --name $job_name \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --download-path mxnet_training_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the trained outputs in worker logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> mxnet_training_result/artifacts/azureml-logs/70_driver_log_2.txt <==\r\n",
      "[06:12:33] src/base.cc:51: Upgrade advisory: this mxnet has been built against cuda library version 9000, which is older than the oldest version tested by CI (10000).  Set MXNET_CUDA_LIB_CHECKING=0 to quiet this warning.\r\n",
      "Downloading /root/.mxnet/datasets/mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-images-idx3-ubyte.gz...\r\n",
      "Downloading /root/.mxnet/datasets/mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-labels-idx1-ubyte.gz...\r\n",
      "Downloading /root/.mxnet/datasets/mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-images-idx3-ubyte.gz...\r\n",
      "Downloading /root/.mxnet/datasets/mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-labels-idx1-ubyte.gz...\r\n",
      "Epoch 0: Accuracy 0.938700\r\n",
      "Epoch 1: Accuracy 0.951600\r\n",
      "Epoch 2: Accuracy 0.961200\r\n",
      "Epoch 3: Accuracy 0.966900\r\n",
      "Epoch 4: Accuracy 0.970800\r\n",
      "[2022-08-24T06:13:41.278757] Command finished with exit code 0 interpreted as return code 0\r\n",
      "\r\n",
      "\r\n",
      "[2022-08-24T06:13:41.279617] The experiment completed successfully. Finalizing run...\r\n",
      "[2022-08-24T06:13:41.279769] Finished context manager injector.\r\n",
      "\r\n",
      "==> mxnet_training_result/artifacts/azureml-logs/70_driver_log_3.txt <==\r\n",
      "[06:12:33] src/base.cc:51: Upgrade advisory: this mxnet has been built against cuda library version 9000, which is older than the oldest version tested by CI (10000).  Set MXNET_CUDA_LIB_CHECKING=0 to quiet this warning.\r\n",
      "Downloading /root/.mxnet/datasets/mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-images-idx3-ubyte.gz...\r\n",
      "Downloading /root/.mxnet/datasets/mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-labels-idx1-ubyte.gz...\r\n",
      "Downloading /root/.mxnet/datasets/mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-images-idx3-ubyte.gz...\r\n",
      "Downloading /root/.mxnet/datasets/mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-labels-idx1-ubyte.gz...\r\n",
      "Epoch 0: Accuracy 0.938700\r\n",
      "Epoch 1: Accuracy 0.951600\r\n",
      "Epoch 2: Accuracy 0.961200\r\n",
      "Epoch 3: Accuracy 0.966900\r\n",
      "Epoch 4: Accuracy 0.970800\r\n",
      "[2022-08-24T06:13:41.257797] Command finished with exit code 0 interpreted as return code 0\r\n",
      "\r\n",
      "\r\n",
      "[2022-08-24T06:13:41.258669] The experiment completed successfully. Finalizing run...\r\n",
      "[2022-08-24T06:13:41.258822] Finished context manager injector.\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 15 mxnet_training_result/artifacts/azureml-logs/70_driver_log_2.txt \\\n",
    "  mxnet_training_result/artifacts/azureml-logs/70_driver_log_3.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Remove cluster (Clean-up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting compute cluster01 \n",
      ".................................................................................................................Done.\n",
      "(9m 30s)\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute delete --name cluster01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
