{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minecraft Reinforcement Learning on Ray cluster with Azure Machine Learning\n",
    "\n",
    "In this notebook, we run scaled distributed reinforcement learning (RL) with Ray framework in Azure Machine Learning.<br>\n",
    "This example is based on [this example](https://github.com/tsmatz/minecraft-rl-on-ray-cluster), in which the agent will learn to solve the maze in Minecraft.\n",
    "\n",
    "Using Azure Machine Learning, the computing instances will automatically be scaled down to 0 instances when the training has completed.<br>\n",
    "This example also sends logs (episode total and reward mean in each training iterations) to Azure Machine Learning workspace.\n",
    "\n",
    "To run this notebook,\n",
    "\n",
    "1. Create new \"Machine Learning\" resource in [Azure Portal](https://portal.azure.com/).\n",
    "2. Install Azure Machine Learning CLI v2 on Ubuntu as follows\n",
    "\n",
    "```\n",
    "# install Azure CLI\n",
    "curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n",
    "# install AML CLI extension\n",
    "az extension add --name ml\n",
    "```\n",
    "\n",
    "> Note : It’s better to run on GPU for practical training. Change configuration for running this example on GPU. (This example is for getting started, and runs on CPU.)\n",
    "\n",
    "> Note : You can now also use Python package ```ray-on-aml``` for running ray cluster on Azure Machine Learning. (See [here](https://github.com/microsoft/ray-on-aml).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create script for RL training (train_agent.py)\n",
    "\n",
    "Save a script file (```train_agent.py```) for Ray RLlib training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script-minecraftrl'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script-minecraftrl/train_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script-minecraftrl/train_agent.py\n",
    "import os\n",
    "import ray\n",
    "import ray.tune as tune\n",
    "import argparse\n",
    "import mlflow\n",
    "import mpi4py\n",
    "from mpi4py import MPI\n",
    "import socket\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--num_workers\",\n",
    "    type=int,\n",
    "    required=False,\n",
    "    default=1,\n",
    "    help=\"number of ray workers\")\n",
    "parser.add_argument(\"--num_gpus\",\n",
    "    type=int,\n",
    "    required=False,\n",
    "    default=0,\n",
    "    help=\"number of gpus\")\n",
    "parser.add_argument(\"--num_cpus_per_worker\",\n",
    "    type=int,\n",
    "    required=False,\n",
    "    default=1,\n",
    "    help=\"number of cores per worker\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Function for stopping a learner when successful training\n",
    "def stop_check(trial_id, result):\n",
    "    return result[\"episode_reward_mean\"] >= 85\n",
    "\n",
    "# Function for logging in Azure Machine Learning workspace\n",
    "# (Callback on train result to record metrics returned by trainer)\n",
    "def on_train_result(info):\n",
    "    mlflow.log_metrics({\n",
    "        'episode_reward_mean': info[\"result\"][\"episode_reward_mean\"],\n",
    "        'episodes_total': info[\"result\"][\"episodes_total\"]\n",
    "    })\n",
    "\n",
    "mpi_comm = MPI.COMM_WORLD\n",
    "mpi_rank = mpi_comm.Get_rank()\n",
    "# mpi_rank = int(os.getenv(\"OMPI_COMM_WORLD_RANK\"))\n",
    "\n",
    "#\n",
    "# Wait for head and all workers\n",
    "#\n",
    "if mpi_rank == 0 :\n",
    "    # wait for all workers\n",
    "    for n in range(args.num_workers):\n",
    "        if n != 0:\n",
    "            req = mpi_comm.irecv(source=n, tag=n)\n",
    "            data = req.wait()\n",
    "else:\n",
    "    # send ready message to head\n",
    "    req = mpi_comm.isend(\"ready\", dest=0, tag=mpi_rank)\n",
    "    req.wait()\n",
    "\n",
    "#\n",
    "# start training (only on rank 0)\n",
    "#\n",
    "if mpi_rank == 0 :\n",
    "    ray.init(address=\"auto\")\n",
    "\n",
    "    ray.tune.run(\n",
    "        \"IMPALA\",\n",
    "        config={\n",
    "            \"log_level\": \"WARN\",\n",
    "            \"env\": \"custom_malmo_env:MalmoMazeEnv-v0\",\n",
    "            \"num_workers\": args.num_workers,\n",
    "            \"num_gpus\": args.num_gpus,\n",
    "            \"num_cpus_per_worker\": args.num_cpus_per_worker,\n",
    "            \"explore\": True,\n",
    "            \"exploration_config\": {\n",
    "                \"type\": \"EpsilonGreedy\",\n",
    "                \"initial_epsilon\": 1.0,\n",
    "                \"final_epsilon\": 0.02,\n",
    "                \"epsilon_timesteps\": 500000\n",
    "            },\n",
    "            \"callbacks\": {\"on_train_result\": on_train_result},\n",
    "        },\n",
    "        stop=stop_check,\n",
    "        checkpoint_at_end=True,\n",
    "        checkpoint_freq=2,\n",
    "        local_dir='./outputs'\n",
    "    )\n",
    "\n",
    "    # broadcast completion\n",
    "    data = mpi_comm.bcast({\"status\":\"training done\"}, root=0)\n",
    "else:\n",
    "    # receive broadcast message from head\n",
    "    # (till completing job)\n",
    "    print(\"waiting training to complete ...\")\n",
    "    data = mpi_comm.bcast(None, root=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create script for ray cluster setup (ray_setup.py)\n",
    "\n",
    "Create a shell script for starting Ray cluster (head and workers).<br>\n",
    "I assign the following roles in ray.\n",
    "\n",
    "- Rank 0 : Ray Head\n",
    "- Other Rank : Ray Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script-minecraftrl/ray_start.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile script-minecraftrl/ray_start.sh\n",
    "export LC_ALL=C.UTF-8  # needed for running Ray\n",
    "if [ $OMPI_COMM_WORLD_RANK -eq 0 ]\n",
    "then\n",
    "  ray start --head --port=6379\n",
    "else\n",
    "  ray start --address=\"$AZ_BATCHAI_MPI_MASTER_NODE:6379\" --redis-password=\"5241590000000000\"\n",
    "fi\n",
    "unset LC_ALL           # removed for running Malmo\n",
    "# status=$(ray status)\n",
    "# if [[ -z \"$status\" ]]\n",
    "# then\n",
    "#     echo \"ray not running\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submit Job in Azure Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for connecting to Azure Machine Learning workspace\n",
    "\n",
    "Login to Azure and prepare for connecting to Azure Machine Learning (AML) workspace.<br>\n",
    "Please fill the following subscription id, AML workspace name, and resource group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s {AZURE_SUBSCRIPTION_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resource_group = \"{AML_RESOURCE_GROUP_NAME}\"\n",
    "my_workspace = \"{AML_WORSPACE_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cluster (multiple nodes)\n",
    "\n",
    "Create a remote cluster with 3 nodes - 1 head node and 2 worker nodes.\n",
    "\n",
    "Here we use ```Standard_D3_v2``` for VMs, but it's better to use GPU VMs for this training in practical use. (Dockerfile and pip packages should also be changed for running on GPU.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/computes/cluster01\",\n",
      "  \"idle_time_before_scale_down\": 120,\n",
      "  \"location\": \"eastus\",\n",
      "  \"max_instances\": 3,\n",
      "  \"min_instances\": 0,\n",
      "  \"name\": \"cluster01\",\n",
      "  \"network_settings\": {},\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"size\": \"STANDARD_D3_V2\",\n",
      "  \"ssh_public_access_enabled\": true,\n",
      "  \"tier\": \"dedicated\",\n",
      "  \"type\": \"amlcompute\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute create --name cluster01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --type amlcompute \\\n",
    "  --min-instances 0 \\\n",
    "  --max-instances 3 \\\n",
    "  --size Standard_D3_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AML environment for running Minecraft RL\n",
    "\n",
    "To generate an AML environment with custom container image, first I prepare Dockerfile.<br>\n",
    "In this conatiner image, the following is installed and configured. (See [here](https://github.com/tsmatz/minecraft-rl-on-ray-cluster) for details.)\n",
    "\n",
    "- Open MPI 3.1.2\n",
    "- Ray 1.6.0 with TensorFlow 2.x backend\n",
    "- Project Malmo with Minecraft (needs Java 8)\n",
    "- Custom Gym environment to run Minecraft agent for Maze (see [here](https://github.com/tsmatz/minecraft-rl-on-ray-cluster/tree/master/Malmo_Maze_Sample/custom_malmo_env))\n",
    "- MLflow for Azure ML logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "context_folder = './docker-context-minecraftrl'\n",
    "os.makedirs(context_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing docker-context-minecraftrl/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker-context-minecraftrl/Dockerfile\n",
    "FROM ubuntu:18.04\n",
    "\n",
    "#\n",
    "# Note : This image is configured for running on CPU\n",
    "# (not configured for running on GPU)\n",
    "#\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Prerequisites settings\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y apt-utils git rsync wget bzip2 gcc g++ make\n",
    "\n",
    "# Install Python\n",
    "RUN apt-get install -y python3.6 && \\\n",
    "    apt-get install -y python3-pip && \\\n",
    "    pip3 install --upgrade pip\n",
    "RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.6 1\n",
    "\n",
    "# Install Open MPI\n",
    "\n",
    "#RUN wget -q https://www.open-mpi.org/software/ompi/v1.10/downloads/openmpi-1.10.4.tar.gz && \\\n",
    "#    tar -xzf openmpi-1.10.4.tar.gz && \\\n",
    "#    cd openmpi-1.10.4 && \\\n",
    "#    ./configure --prefix=/usr/local/mpi && \\\n",
    "#    make -j\"$(nproc)\" install && \\\n",
    "#    cd .. && \\\n",
    "#    rm -rf /openmpi-1.10.4 && \\\n",
    "#    rm -rf openmpi-1.10.4.tar.gz\n",
    "#ENV PATH=/usr/local/mpi/bin:$PATH \\\n",
    "#    LD_LIBRARY_PATH=/usr/local/mpi/lib:$LD_LIBRARY_PATH\n",
    "\n",
    "ENV OPENMPI_VERSION 3.1.2\n",
    "RUN mkdir /tmp/openmpi && \\\n",
    "    cd /tmp/openmpi && \\\n",
    "    wget https://download.open-mpi.org/release/open-mpi/v3.1/openmpi-3.1.2.tar.gz && \\\n",
    "    tar zxf openmpi-3.1.2.tar.gz && \\\n",
    "    cd openmpi-3.1.2 && \\\n",
    "    ./configure --enable-orterun-prefix-by-default && \\\n",
    "    make -j $(nproc) all && \\\n",
    "    make install && \\\n",
    "    ldconfig && \\\n",
    "    rm -rf /tmp/openmpi\n",
    "RUN pip3 install mpi4py\n",
    "\n",
    "# Install Java 8 (JDK)\n",
    "RUN apt-get install -y openjdk-8-jdk\n",
    "ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
    "\n",
    "# Install Ray with TensorFlow 2.x\n",
    "RUN pip3 install gym==0.21.0 lxml numpy pillow && \\\n",
    "    pip3 install tensorflow==2.4.1 ray[default]==1.6.0 ray[rllib]==1.6.0 ray[tune]==1.6.0 attrs==19.1.0 pandas\n",
    "\n",
    "# Install Desktop Components for Headless\n",
    "RUN apt-get install -y xvfb && \\\n",
    "    echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections && \\\n",
    "    apt-get install -y lxde\n",
    "\n",
    "# Install mlflow for logging\n",
    "# (Fix version for python 3.6 support)\n",
    "RUN pip3 install mlflow==1.23.1 azureml-mlflow==1.44.0\n",
    "\n",
    "# Install Malmo\n",
    "RUN pip3 install --index-url https://test.pypi.org/simple/ malmo==0.36.0\n",
    "ENV MALMO_PATH=/malmo_package\n",
    "WORKDIR $MALMO_PATH\n",
    "RUN python3 -c \"import malmo.minecraftbootstrap; malmo.minecraftbootstrap.download();\"\n",
    "ENV MALMO_XSD_PATH=$MALMO_PATH/MalmoPlatform/Schemas\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Install custom Gym env\n",
    "RUN git clone https://github.com/tsmatz/minecraft-rl-on-ray-cluster\n",
    "RUN cd minecraft-rl-on-ray-cluster && \\\n",
    "    pip3 install Malmo_Maze_Sample/\n",
    "\n",
    "EXPOSE 6379 8265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an AML environment with above docker configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing env_minecraft_rl.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile env_minecraft_rl.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json\n",
    "name: minecraft-rl-env\n",
    "build:\n",
    "  path: docker-context-minecraftrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading docker-context-minecraftrl (0.0 MBs): 100%|█| 2398/2398 [00:00<00:00, \u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"build\": {\n",
      "    \"dockerfile_path\": \"Dockerfile\",\n",
      "    \"path\": \"https://ws016125543015.blob.core.windows.net/azureml-blobstore-fd7d98c2-a2bd-44e4-8c0d-52c3bf7b2f7c/LocalUpload/7fbb1733faa9d8afa2f9b0ae7becca6d/docker-context-minecraftrl/\"\n",
      "  },\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-08-23T03:35:24.386503+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2022-08-23T03:35:24.386503+00:00\",\n",
      "    \"last_modified_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/environments/minecraft-rl-env/versions/1\",\n",
      "  \"name\": \"minecraft-rl-env\",\n",
      "  \"os_type\": \"linux\",\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"tags\": {},\n",
      "  \"version\": \"1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml environment create --file env_minecraft_rl.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Job\n",
    "\n",
    "Now let's run Minecraft RL training on Ray cluster.\n",
    "\n",
    "This will launch Minecraft instance (process) with specific port, when it starts. So make sure that no node is running in starting. (When you run instance twice in the same node, the training will fail.)\n",
    "\n",
    "> Note : For the first time to run, it builds docker image and then takes a long time to start training. (Once it's registered, it can speed up to start.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_minecraft_rl.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_minecraft_rl.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "code: script-minecraftrl\n",
    "command: |\n",
    "  bash ray_start.sh\n",
    "  python train_agent.py --num_workers ${{inputs.num_workers}} --num_gpus ${{inputs.num_gpus}} --num_cpus_per_worker ${{inputs.num_cpus_per_worker}}\n",
    "  ray stop\n",
    "inputs:\n",
    "  num_workers: 3\n",
    "  num_gpus: 0\n",
    "  num_cpus_per_worker: 3\n",
    "environment: azureml:minecraft-rl-env@latest\n",
    "compute: azureml:cluster01\n",
    "display_name: minecraft_rl_test\n",
    "experiment_name: minecraft_rl_test\n",
    "resources:\n",
    "  instance_count: 3\n",
    "distribution:\n",
    "  type: mpi\n",
    "  process_count_per_instance: 1\n",
    "description: Minecraft RL in Ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading script-minecraftrl (0.0 MBs): 100%|█| 2866/2866 [00:00<00:00, 94838.50\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"code\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/codes/4e30d67a-617a-4d08-b012-6a0d0fc4e11a/versions/1\",\n",
      "  \"command\": \"bash ray_start.sh\\npython train_agent.py --num_workers ${{inputs.num_workers}} --num_gpus ${{inputs.num_gpus}} --num_cpus_per_worker ${{inputs.num_cpus_per_worker}}\\nray stop\\n\",\n",
      "  \"compute\": \"azureml:cluster01\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-08-23T03:37:19.631744+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"Minecraft RL in Ray cluster\",\n",
      "  \"display_name\": \"minecraft_rl_test\",\n",
      "  \"distribution\": {\n",
      "    \"process_count_per_instance\": 1,\n",
      "    \"type\": \"mpi\"\n",
      "  },\n",
      "  \"environment\": \"azureml:minecraft-rl-env:1\",\n",
      "  \"environment_variables\": {},\n",
      "  \"experiment_name\": \"minecraft_rl_test\",\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/magenta_salt_7zmmbkyb42\",\n",
      "  \"inputs\": {\n",
      "    \"num_cpus_per_worker\": 3,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_workers\": 3\n",
      "  },\n",
      "  \"name\": \"magenta_salt_7zmmbkyb42\",\n",
      "  \"outputs\": {\n",
      "    \"default\": {\n",
      "      \"mode\": \"rw_mount\",\n",
      "      \"path\": \"azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.magenta_salt_7zmmbkyb42\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"parameters\": {},\n",
      "  \"properties\": {\n",
      "    \"ContentSnapshotId\": \"a33d761d-f5d0-45e6-8013-001d72292be8\",\n",
      "    \"_azureml.ComputeTargetType\": \"amlctrain\"\n",
      "  },\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"resources\": {\n",
      "    \"instance_count\": 3,\n",
      "    \"properties\": {}\n",
      "  },\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/magenta_salt_7zmmbkyb42?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/AML-rg/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "      \"job_service_type\": \"Studio\"\n",
      "    },\n",
      "    \"Tracking\": {\n",
      "      \"endpoint\": \"azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01?\",\n",
      "      \"job_service_type\": \"Tracking\"\n",
      "    }\n",
      "  },\n",
      "  \"status\": \"Starting\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"command\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job create --file train_minecraft_rl.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [Azure Machine Learning studio](https://ml.azure.com/), and see driver's log on rank 0.<br>\n",
    "You will find that it shows the log outputs (such as, progressing episode count, reward mean) in each training iterations.\n",
    "\n",
    "![driver log](./azureml_minecraft_rl_ray_cluster/driver_log.jpg)\n",
    "\n",
    "When you wait for a while, you will also see the trained parameter's results, called checkpoint, in the outputs. (You can also check all progressing results in ```progress.csv```.)\n",
    "\n",
    "![checkpoint result](./azureml_minecraft_rl_ray_cluster/checkpoint_output.jpg)\n",
    "\n",
    "**This training requires about 1 day for completion when it's run on GPU.**<br>\n",
    "Please cancel this job, if you don't need to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove cluster (Clean-up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml compute delete --name cluster01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
