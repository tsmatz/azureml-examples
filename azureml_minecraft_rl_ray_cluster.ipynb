{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minecraft Reinforcement Learning on Ray cluster with Azure Machine Learning\n",
    "\n",
    "In this notebook, we run scaled distributed reinforcement learning (RL) with Ray framework in Azure Machine Learning.<br>\n",
    "This example is based on [here](https://github.com/tsmatz/minecraft-rl-on-ray-cluster), in which the agent will learn to solve the maze in Minecraft RL, Project Malmo.\n",
    "\n",
    "Using Azure Machine Learning, the computing instances will automatically be scaled down to 0 instances when the training has completed.<br>\n",
    "This example also sends logs (episode total and reward mean in each training iterations) to Azure Machine Learning workspace.\n",
    "\n",
    "> Note : Itâ€™s better to run on GPU for practical training. Change configuration for running this example on GPU. (This example is for getting started, and runs on CPU.)\n",
    "\n",
    "> Note : You can now also use Python package ```ray-on-aml``` for running ray cluster on Azure Machine Learning. (See [here](https://github.com/james-tn/ray-on-aml).)",
    "\n",
    "To run this notebook,\n",
    "\n",
    "1. Create new \"Machine Learning\" resource in [Azure Portal](https://portal.azure.com/).\n",
    "2. Install Azure Machine Learning SDK (core package) as follows\n",
    "\n",
    "```\n",
    "pip install azureml-core\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create script for RL training (train_ray_cluster.py)\n",
    "\n",
    "Save a script file (```train_ray_cluster.py```) for Ray RLlib training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/train_ray_cluster.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train_ray_cluster.py\n",
    "import os\n",
    "import ray\n",
    "import ray.tune as tune\n",
    "from azureml.core import Run\n",
    "\n",
    "# Function for stopping a learner when successful training\n",
    "def stop_check(trial_id, result):\n",
    "    return result[\"episode_reward_mean\"] >= 85\n",
    "\n",
    "# Function for logging in Azure Machine Learning workspace\n",
    "# (Callback on train result to record metrics returned by trainer)\n",
    "def on_train_result(info):\n",
    "    run = Run.get_context()\n",
    "    run.log(\n",
    "        name='episode_reward_mean',\n",
    "        value=info[\"result\"][\"episode_reward_mean\"])\n",
    "    run.log(\n",
    "        name='episodes_total',\n",
    "        value=info[\"result\"][\"episodes_total\"])\n",
    "\n",
    "def train_agent(num_workers, num_gpus, num_cpus_per_worker):\n",
    "    ray.init(address=\"auto\")\n",
    "\n",
    "    ray.tune.run(\n",
    "        \"IMPALA\",\n",
    "        config={\n",
    "            \"log_level\": \"WARN\",\n",
    "            \"env\": \"custom_malmo_env:MalmoMazeEnv-v0\",\n",
    "            \"num_workers\": num_workers,\n",
    "            \"num_gpus\": num_gpus,\n",
    "            \"num_cpus_per_worker\": num_cpus_per_worker,\n",
    "            \"explore\": True,\n",
    "            \"exploration_config\": {\n",
    "                \"type\": \"EpsilonGreedy\",\n",
    "                \"initial_epsilon\": 1.0,\n",
    "                \"final_epsilon\": 0.02,\n",
    "                \"epsilon_timesteps\": 500000\n",
    "            },\n",
    "            \"callbacks\": {\"on_train_result\": on_train_result},\n",
    "        },\n",
    "        stop=stop_check,\n",
    "        checkpoint_at_end=True,\n",
    "        checkpoint_freq=2,\n",
    "        local_dir='./outputs'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create script for entry (start_server.py)\n",
    "\n",
    "Create an entry script for starting Ray cluster (head and workers) and invoking RL training.<br>\n",
    "Here we run 3 nodes with the following roles.\n",
    "\n",
    "- Rank 0 : Ray Head\n",
    "- Rank 1 : Ray Worker\n",
    "- Rank 2 : Ray Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/start_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/start_server.py\n",
    "import argparse\n",
    "import os\n",
    "from mpi4py import MPI\n",
    "import socket\n",
    "\n",
    "from train_ray_cluster import train_agent\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--num_workers\",\n",
    "    type=int,\n",
    "    required=False,\n",
    "    default=1,\n",
    "    help=\"number of ray workers\")\n",
    "parser.add_argument(\"--num_gpus\",\n",
    "    type=int,\n",
    "    required=False,\n",
    "    default=0,\n",
    "    help=\"number of gpus\")\n",
    "parser.add_argument(\"--num_cpus_per_worker\",\n",
    "    type=int,\n",
    "    required=False,\n",
    "    default=1,\n",
    "    help=\"number of cores per worker\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "mpi_comm = MPI.COMM_WORLD\n",
    "mpi_rank = mpi_comm.Get_rank()\n",
    "if mpi_rank == 0 :\n",
    "    #\n",
    "    # Head Node (Rank 0)\n",
    "    #\n",
    "\n",
    "    # Start Ray Head (Run the following command)\n",
    "    # ray start --head --port=6379\n",
    "    os.environ[\"LC_ALL\"] = \"C.UTF-8\" # Needed for running Ray\n",
    "    os.system(\"ray start --head --port=6379\")\n",
    "    del os.environ[\"LC_ALL\"] # Removed for running Malmo\n",
    "\n",
    "    # Send head address to workers\n",
    "    ipaddr = socket.gethostbyname(socket.gethostname())\n",
    "    header_info = {\n",
    "        \"address\"  : ipaddr + \":6379\"\n",
    "    }\n",
    "    header_info = mpi_comm.bcast(header_info, root=0)\n",
    "\n",
    "    # Wait for staring workers\n",
    "    req = mpi_comm.irecv(source=1, tag=1)\n",
    "    data = req.wait()\n",
    "    req = mpi_comm.irecv(source=2, tag=2)\n",
    "    data = req.wait()\n",
    "\n",
    "    # Run previous script !\n",
    "    try:\n",
    "        train_agent(args.num_workers, args.num_gpus, args.num_cpus_per_worker)\n",
    "        print(\"Training has done !\")\n",
    "        os.system(\"ray stop\")\n",
    "    except:\n",
    "        data = mpi_comm.bcast({\"status\":\"error\"}, root=0)\n",
    "        os.system(\"ray stop\")\n",
    "        raise\n",
    "\n",
    "    data = mpi_comm.bcast({\"status\":\"done\"}, root=0)\n",
    "\n",
    "else :\n",
    "    #\n",
    "    # Worker Nodes (Rank 1, 2)\n",
    "    #\n",
    "\n",
    "    # Wait for starting header  (with address info)\n",
    "    header_info = mpi_comm.bcast(None, root=0)\n",
    "    header_address = header_info[\"address\"]\n",
    "\n",
    "    # Start Ray Worker (Run the following command)\n",
    "    # ray start --address='xx.xx.xx.xx:6379' --redis-password=\"5241590000000000\"\n",
    "    os.environ[\"LC_ALL\"] = \"C.UTF-8\" # Needed for running Ray\n",
    "    os.system(\"ray start --address=\\\"\" + header_address + \"\\\" --redis-password=\\\"5241590000000000\\\"\")\n",
    "    del os.environ[\"LC_ALL\"] # Removed for running Malmo\n",
    "\n",
    "    # Send ready message to head\n",
    "    req = mpi_comm.isend('ready', dest=0, tag=mpi_rank)\n",
    "    req.wait()\n",
    "\n",
    "    # Wait for completing job (with status info)\n",
    "    status_info = mpi_comm.bcast(None, root=0)\n",
    "    os.system(\"ray stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Connect to Azure Machine Learning (Create AML config)\n",
    "\n",
    "Connect to your Azure Machine Learning (AML) workspace.<br>\n",
    "Please fill the following workspace name, subscription id, and resource group name. (You can get these values on AML resource blade in Azure Portal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace(\n",
    "    workspace_name = \"{AML WORKSPACE NAME}\",\n",
    "    subscription_id = \"{SUBSCRIPTION ID}\",\n",
    "    resource_group = \"{RESOURCE GROUP NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create cluster (multiple nodes)\n",
    "\n",
    "Create a remote cluster with 3 nodes - 1 head node and 2 worker nodes.\n",
    "\n",
    "Here we use ```Standard_D3_v2``` for VMs, but it's better to use GPU VMs for this training in practical use. (Dockerfile and pip packages should also be changed for running on GPU.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new.\n",
      "InProgress....\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded......................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    " \n",
    "# Create AML compute (or Get existing one)\n",
    "# (Total 3 : 1 Header, 2 Workers)\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name='cluster01')\n",
    "    print('found existing:', compute_target.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='Standard_D3_v2',\n",
    "        min_nodes=0,\n",
    "        max_nodes=3,\n",
    "        location=\"eastus\")\n",
    "    compute_target = ComputeTarget.create(ws, 'cluster01', compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate config for run\n",
    "\n",
    "Generate a script run configuration in AML.<br>\n",
    "Here we generate custom container image, in which the following is installed and configured. (See [here](https://github.com/tsmatz/minecraft-rl-on-ray-cluster) for details.)\n",
    "\n",
    "- Open MPI 3.1.2\n",
    "- Azure ML Python SDK\n",
    "- Ray 1.6.0 with TensorFlow 2.x backend\n",
    "- Project Malmo with Minecraft (needs Java 8)\n",
    "- Custom Gym env for running Maze agent (see [here](https://github.com/tsmatz/minecraft-rl-on-ray-cluster/tree/master/Malmo_Maze_Sample/custom_malmo_env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core import Run, ScriptRunConfig\n",
    "from azureml.core.runconfig import DockerConfiguration, MpiConfiguration\n",
    "\n",
    "# Create environment\n",
    "# (All components are alreday setup in this image.)\n",
    "env = Environment('minecraft-rl')\n",
    "env.python.user_managed_dependencies=True\n",
    "env.python.interpreter_path = \"/usr/bin/python\"\n",
    "env.docker.base_image = None\n",
    "env.docker.base_dockerfile = \"\"\"\n",
    "FROM ubuntu:18.04\n",
    "\n",
    "#\n",
    "# Note : This image is not configured for running on GPU\n",
    "#\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Prerequisites settings\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y apt-utils git rsync wget bzip2 gcc g++ make\n",
    "\n",
    "# Install Python\n",
    "RUN apt-get install -y python3.6 && \\\n",
    "    apt-get install -y python3-pip && \\\n",
    "    pip3 install --upgrade pip\n",
    "RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.6 1\n",
    "\n",
    "# Install Open MPI\n",
    "\n",
    "#RUN wget -q https://www.open-mpi.org/software/ompi/v1.10/downloads/openmpi-1.10.4.tar.gz && \\\n",
    "#    tar -xzf openmpi-1.10.4.tar.gz && \\\n",
    "#    cd openmpi-1.10.4 && \\\n",
    "#    ./configure --prefix=/usr/local/mpi && \\\n",
    "#    make -j\"$(nproc)\" install && \\\n",
    "#    cd .. && \\\n",
    "#    rm -rf /openmpi-1.10.4 && \\\n",
    "#    rm -rf openmpi-1.10.4.tar.gz\n",
    "#ENV PATH=/usr/local/mpi/bin:$PATH \\\n",
    "#    LD_LIBRARY_PATH=/usr/local/mpi/lib:$LD_LIBRARY_PATH\n",
    "\n",
    "ENV OPENMPI_VERSION 3.1.2\n",
    "RUN mkdir /tmp/openmpi && \\\n",
    "    cd /tmp/openmpi && \\\n",
    "    wget https://download.open-mpi.org/release/open-mpi/v3.1/openmpi-3.1.2.tar.gz && \\\n",
    "    tar zxf openmpi-3.1.2.tar.gz && \\\n",
    "    cd openmpi-3.1.2 && \\\n",
    "    ./configure --enable-orterun-prefix-by-default && \\\n",
    "    make -j $(nproc) all && \\\n",
    "    make install && \\\n",
    "    ldconfig && \\\n",
    "    rm -rf /tmp/openmpi\n",
    "RUN pip3 install mpi4py\n",
    "\n",
    "# Install Java 8 (JDK)\n",
    "RUN apt-get install -y openjdk-8-jdk\n",
    "ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
    "\n",
    "# Install Ray with TensorFlow 2.x\n",
    "RUN pip3 install gym lxml numpy pillow && \\\n",
    "    pip3 install tensorflow==2.4.1 ray[default]==1.6.0 ray[rllib]==1.6.0 ray[tune]==1.6.0 attrs==19.1.0 pandas\n",
    "\n",
    "# Install Desktop Components for Headless\n",
    "RUN apt-get install -y xvfb && \\\n",
    "    echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections && \\\n",
    "    apt-get install -y lxde\n",
    "\n",
    "# Install Azure ML core\n",
    "RUN pip3 install azureml-core\n",
    "\n",
    "# Install Malmo\n",
    "RUN pip3 install --index-url https://test.pypi.org/simple/ malmo==0.36.0\n",
    "ENV MALMO_PATH=/malmo_package\n",
    "WORKDIR $MALMO_PATH\n",
    "RUN python3 -c \"import malmo.minecraftbootstrap; malmo.minecraftbootstrap.download();\"\n",
    "ENV MALMO_XSD_PATH=$MALMO_PATH/MalmoPlatform/Schemas\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Install custom Gym env\n",
    "RUN git clone https://github.com/tsmatz/minecraft-rl-on-ray-cluster\n",
    "RUN cd minecraft-rl-on-ray-cluster && \\\n",
    "    pip3 install Malmo_Maze_Sample/\n",
    "\n",
    "EXPOSE 6379 8265\n",
    "\"\"\"\n",
    "\n",
    "# register environment to re-use later\n",
    "env.register(workspace=ws)\n",
    "## # speed up by using the existing environment\n",
    "## env = Environment.get(ws, name='minecraft-rl')\n",
    "\n",
    "# create script run config\n",
    "src = ScriptRunConfig(\n",
    "    source_directory='./script',\n",
    "    script='start_server.py',\n",
    "    arguments=[\n",
    "        '--num_workers', 3,\n",
    "        '--num_cpus_per_worker', 3], \n",
    "    compute_target=compute_target,\n",
    "    environment=env,\n",
    "    docker_runtime_config=DockerConfiguration(use_docker=True),\n",
    "    distributed_job_config=MpiConfiguration(process_count_per_node=1, node_count=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run !\n",
    "\n",
    "Now let's run Minecraft RL training on Ray.\n",
    "\n",
    "This training requires about 1 day for completion when it's run on GPU.<br>\n",
    "You can see the metrics (reward means and episode total) on Azure Machine Learning studio UI during the training. (See \"Experiments\" in AML studio.)\n",
    "\n",
    "> Note : For the first time to run, it builds docker image and takes a long time to start training. (Once it's registered, it can speed up to start.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: minecraft_rl_test_1634097472_c2a1da1f\n",
      "Web View: https://ml.azure.com/runs/minecraft_rl_test_1634097472_c2a1da1f?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/TEST20211011/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_594e4f8070c2df7271bfb89a011c5981a0bb209292aae30e4ddec4eb22184b80_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2021-10-13T04:02:14Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/minecraft_rl_test_1634097472_c2a1da1f/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/minecraft_rl_test_1634097472_c2a1da1f/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=185369 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/minecraft_rl_test_1634097472_c2a1da1f/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-10-13T04:02:14Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/minecraft_rl_test_1634097472_c2a1da1f/mounts/workspaceblobstore\n",
      "2021-10-13T04:02:15Z The vmsize standard_d3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-10-13T04:02:15Z Starting output-watcher...\n",
      "2021-10-13T04:02:15Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_8246df9e4b586fcfa0c160abcb816314\n",
      "284055322776: Pulling fs layer\n",
      "f83c636e4934: Pulling fs layer\n",
      "7df8bb746cd0: Pulling fs layer\n",
      "47735b8c0eb3: Pulling fs layer\n",
      "eebd3b29fafc: Pulling fs layer\n",
      "30d431597b87: Pulling fs layer\n",
      "999763fa8229: Pulling fs layer\n",
      "d7b0989b97b4: Pulling fs layer\n",
      "72e2135636c5: Pulling fs layer\n",
      "67b37d23ed59: Pulling fs layer\n",
      "2e35306cc619: Pulling fs layer\n",
      "132a94624715: Pulling fs layer\n",
      "85b7c00d7dae: Pulling fs layer\n",
      "ee4b1b6cd986: Pulling fs layer\n",
      "b47e6cc85603: Pulling fs layer\n",
      "84bff118ccfe: Pulling fs layer\n",
      "a6512b5036cb: Pulling fs layer\n",
      "47735b8c0eb3: Waiting\n",
      "eebd3b29fafc: Waiting\n",
      "30d431597b87: Waiting\n",
      "999763fa8229: Waiting\n",
      "d7b0989b97b4: Waiting\n",
      "72e2135636c5: Waiting\n",
      "67b37d23ed59: Waiting\n",
      "2e35306cc619: Waiting\n",
      "132a94624715: Waiting\n",
      "85b7c00d7dae: Waiting\n",
      "ee4b1b6cd986: Waiting\n",
      "b47e6cc85603: Waiting\n",
      "84bff118ccfe: Waiting\n",
      "a6512b5036cb: Waiting\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_594e4f8070c2df7271bfb89a011c5981a0bb209292aae30e4ddec4eb22184b80_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-10-13T04:03:12.382804] Entering job preparation.\n",
      "[2021-10-13T04:03:13.736186] Starting job preparation.\n",
      "[2021-10-13T04:03:13.736227] Extracting the control code.\n",
      "[2021-10-13T04:03:13.736565] Starting extract_project.\n",
      "[2021-10-13T04:03:13.736614] Starting to extract zip file.\n",
      "[2021-10-13T04:03:13.756606] Finished extracting zip file.\n",
      "[2021-10-13T04:03:13.761588] Using urllib.request Python 3.0 or later\n",
      "[2021-10-13T04:03:13.761665] Start fetching snapshots.\n",
      "[2021-10-13T04:03:13.761705] Start fetching snapshot.\n",
      "[2021-10-13T04:03:13.761749] Retrieving project from snapshot: 7429a6b8-6f96-4736-aab4-9cb438bc91be\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 340\n",
      "[2021-10-13T04:03:14.018167] Finished fetching snapshot.\n",
      "[2021-10-13T04:03:14.018211] Finished fetching snapshots.\n",
      "[2021-10-13T04:03:14.018226] Finished extract_project.\n",
      "[2021-10-13T04:03:14.018417] Finished fetching and extracting the control code.\n",
      "[2021-10-13T04:03:14.022225] downloadDataStore - Download from datastores if requested.\n",
      "[2021-10-13T04:03:14.023295] Start run_history_prep.\n",
      "[2021-10-13T04:03:14.028735] Entering context manager injector.\n",
      "[2021-10-13T04:03:14.033498] downloadDataStore completed\n",
      "[2021-10-13T04:03:14.035163] Job preparation is complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log_0.txt\n",
      "==========================================\n",
      "\n",
      "[2021-10-13T04:03:22.647504] Entering context manager injector.\n",
      "[2021-10-13T04:03:23.288604] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['start_server.py', '--num_workers', '3', '--num_cpus_per_worker', '3'])\n",
      "This is an MPI job. Rank:0\n",
      "Script type = None\n",
      "[2021-10-13T04:03:23.293788] Entering Run History Context Manager.\n",
      "[2021-10-13T04:03:24.177134] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/minecraft_rl_test_1634097472_c2a1da1f/wd/azureml/minecraft_rl_test_1634097472_c2a1da1f\n",
      "[2021-10-13T04:03:24.177193] Preparing to call script [start_server.py] with arguments:['--num_workers', '3', '--num_cpus_per_worker', '3']\n",
      "[2021-10-13T04:03:24.177223] After variable expansion, calling script [start_server.py] with arguments:['--num_workers', '3', '--num_cpus_per_worker', '3']\n",
      "\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_register: registering framework btl components\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_register: found loaded component tcp\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_register: component tcp register function successful\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_register: found loaded component sm\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_register: found loaded component self\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_register: component self register function successful\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_register: found loaded component vader\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_register: component vader register function successful\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_open: opening btl components\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_open: found loaded component tcp\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_open: component tcp open function successful\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_open: found loaded component self\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_open: component self open function successful\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_open: found loaded component vader\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: components_open: component vader open function successful\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] select: initializing btl component tcp\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: Attempting to bind to AF_INET port 1024\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: Successfully bound to AF_INET port 1024\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: my listening v4 socket is 0.0.0.0:1024\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: examining interface eth0\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: using ipv6 interface eth0\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] select: init of component tcp returned success\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] select: initializing btl component self\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] select: init of component self returned success\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] select: initializing btl component vader\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] select: init of component vader returned failure\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: close: component vader closed\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: base: close: unloading component vader\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: bml: Using self btl for send to [[55207,1],0] on node cd14b61fbfe54116be7b7b7e2f4f3ea4000000\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_param_files=/root/.openmpi/mca-params.conf:/usr/local/etc/openmpi-mca-params.conf (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_param_files=/root/.openmpi/mca-params.conf:/usr/local/etc/openmpi-mca-params.conf (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_override_param_file=/usr/local/etc/openmpi-mca-params-override.conf (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_suppress_override_warning=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_param_file_prefix= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_envar_file_prefix= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_param_file_path=/usr/local/share/openmpi/amca-param-sets:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/minecraft_rl_test_1634097472_c2a1da1f/wd/azureml/minecraft_rl_test_1634097472_c2a1da1f (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_param_file_path_force= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_signal=6,7,8,11 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_stacktrace_output=stderr (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_net_private_ipv4=10.0.0.0/8;172.16.0.0/12;192.168.0.0/16;169.254.0.0/16 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_set_max_sys_limits= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_built_with_cuda_support=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_cuda_support=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_leave_pinned=auto (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_leave_pinned=auto (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_leave_pinned_pipeline=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_leave_pinned_pipeline=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_warn_on_fork=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_abort_delay=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_abort_print_stack=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_env_list= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_env_list_delimiter=; (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] dss_buffer_type=non-described (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] dss_buffer_initial_size=2048 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] dss_buffer_threshold_size=4096 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_component_path=/usr/local/lib/openmpi:/root/.openmpi/components (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_component_path=/usr/local/lib/openmpi:/root/.openmpi/components (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_component_show_load_errors=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_component_show_load_errors=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_component_track_load_errors=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_component_disable_dlopen=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_component_disable_dlopen=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_base_verbose=stderr (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca_verbose=stderr (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] dl= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] dl_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] dl_dlopen_filename_suffixes=.so,.dylib,.dll,.sl (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] if= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] if_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] if_base_do_not_resolve=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] if_base_retain_loopback=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_param_check=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_yield_when_idle=false (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_event_tick_rate=-1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_show_handle_leaks=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_no_free_handles=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_show_mpi_alloc_mem_leaks=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_show_mca_params=1 (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_show_mca_params_file= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_preconnect_all=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_have_sparse_group_storage=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_use_sparse_group_storage=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_cuda_support=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_built_with_cuda_support=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_add_procs_cutoff=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_dynamics_enabled=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] async_mpi_init=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] async_mpi_finalize=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_abort_delay=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpi_abort_print_stack=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] ompi_timing=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hook= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hook_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rte= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rte_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_mem_alloc_policy=none (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_mem_bind_failure_action=warn (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_binding_policy=none (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_bind_to_core=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_bind_to_socket=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_report_bindings=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_cpu_list= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_slot_list= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_cpu_set= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_use_hwthreads_as_cpus=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] hwloc_base_topo_file= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] memcpy= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] memcpy_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] memchecker= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] memchecker_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] backtrace= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] backtrace_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] timer= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] timer_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] timer_require_monotonic=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] event= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] event_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] event_libevent2022_event_include=poll (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_event_include=poll (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] shmem= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] shmem_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] shmem_mmap_priority=50 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] shmem_mmap_enable_nfs_warning=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] shmem_mmap_relocate_backing_file=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] shmem_mmap_backing_file_base_dir=/dev/shm (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] reachable= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] reachable_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_cr_verbose=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] ft_cr_enabled=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_cr_enable_timer=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_cr_enable_timer_barrier=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_cr_timer_target_rank=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_cr_is_tool=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_cr_signal=10 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_cr_debug_sigpipe=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] opal_cr_tmp_dir=/tmp (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_base_help_aggregate=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_tmpdir_base=/tmp (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_local_tmpdir_base= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_remote_tmpdir_base= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_top_session_dir=/tmp/ompi.cd14b61fbfe54116be7b7b7e2f4f3ea4000000.0 (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_jobfam_session_dir=/tmp/ompi.cd14b61fbfe54116be7b7b7e2f4f3ea4000000.0/pid.379 (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_no_session_dirs= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_create_session_dirs=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_execute_quiet=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_report_silent_errors=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_debug=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_debug_verbose=-1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_debug_daemons_file=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_debug_daemons=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_progress_thread_debug=-1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_leave_session_attached=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_output_debugger_proctable=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_debugger_test_daemon= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_debugger_test_attach=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_debugger_check_rate=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_do_not_launch=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_daemon_spin=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_daemon_fail=-1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_daemon_fail_delay=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_startup_timeout=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_base_user_debugger=totalview @mpirun@ -a @mpirun_args@ : ddt -n @np@ -start @executable@ @executable_argv@ @single_app@ : fxp @mpirun@ -a @mpirun_args@ (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_default_hostfile=/usr/local/etc/openmpi-default-hostfile (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_default_dash_host= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_node_regex= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_keep_fqdn_hostnames=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_retain_aliases=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_hostname_cutoff=1000 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_hostname_alias_index=1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_xml_output=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_tag_output=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_xml_file= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_timestamp_output=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_show_resolved_nodenames=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_launch_agent=orted (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_fork_agent= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_allocation_required=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_map_stddiag_to_stderr=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_map_stddiag_to_stdout=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_xterm= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_report_launch_progress=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_report_events= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_enable_recovery=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_max_restarts=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_abort_on_non_zero_status=true (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_allowed_exit_without_sync=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_report_child_jobs_separately=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_stat_history_size=1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_no_vm=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_max_vm_size=-1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_set_default_slots=cores (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_display_alloc=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] ras_base_display_alloc=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_display_devel_alloc=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] ras_base_display_devel_alloc=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_soft_locations=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_daemon_cores= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_coll_transports=fabric,ethernet (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_mgmt_transports=oob (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_timeout_for_stack_trace=30 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_fwd_mpirun_port=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pmix_server_uri= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_strip_prefix= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] schizo= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] schizo_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] schizo_base_personalities= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] ess=pmi (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] ess_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] ess_base_stream_buffering=default (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_ess_jobid=3618045953 (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_ess_vpid=0 (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_ess_num_procs=3 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] ess_base_forward_signals= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] ess_hnp_forward_signals= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pmix=^s1,s2,cray,isolated (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pmix_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pmix_base_async_modex=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pmix_base_collect_data=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pmix_base_exchange_timeout=-1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pmix_pmix2x_silence_warning=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] state= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] state_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] state_base_check_fds=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] errmgr= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] errmgr_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] errmgr_default_app_priority=1000 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] routed= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] routed_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] routed_radix=64 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_base_num_progress_threads=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_peer_limit=-1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_peer_retries=2 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_sndbuf=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_rcvbuf=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_if_include=eth0 (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_if_exclude= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_static_ipv4_ports= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_dynamic_ipv4_ports= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_disable_ipv4_family=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_keepalive_time=300 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_keepalive_intvl=20 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_keepalive_probes=9 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_retry_delay=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] oob_tcp_max_recon_attempts=10 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rml= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rml_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rml_base_max_retries=3 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] grpcomm= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] grpcomm_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] grpcomm_direct_priority=85 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] orte_cr_verbose=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] dfs= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] dfs_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] op= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] op_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] allocator= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] allocator_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] allocator_bucket_num_buckets=30 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rcache= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rcache_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rcache_base_vma_tree_items_min=2048 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rcache_base_vma_tree_items_max=16384 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rcache_base_vma_tree_items_inc=2048 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] rcache_grdma_print_stats=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpool= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpool_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpool_hugepage_priority=50 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mpool_hugepage_page_size=2097152 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] bml= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] bml_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] bml_r2_show_unreach_errors=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_base_verbose=30 (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_base_include= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_base_exclude= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_base_warn_component_unused=1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_links=1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_if_include=eth0 (environment)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_if_exclude=127.0.0.1/8,sppp (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_free_list_num=8 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_free_list_max=-1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_free_list_inc=32 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_sndbuf=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_rcvbuf=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_endpoint_cache=30720 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_use_nagle=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_port_min_v4=1024 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_port_range_v4=64511 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_progress_thread=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_warn_all_unfound_interfaces=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_exclusivity=100 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_flags=send,put,inplace,need-ack,need-csum,hetero-rdma (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_atomic_flags= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_rndv_eager_limit=65536 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_eager_limit=65536 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_put_limit=18446744073709551615 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_put_alignment=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_max_send_size=131072 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_rdma_pipeline_send_length=131072 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_rdma_pipeline_frag_size=2147482624 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_min_rdma_pipeline_size=196608 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_latency=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_bandwidth=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_disable_family=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_free_list_num=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_free_list_max=64 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_free_list_inc=8 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_exclusivity=65536 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_flags=send,put,get,inplace (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_atomic_flags= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_rndv_eager_limit=131072 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_eager_limit=1024 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_get_limit=18446744073709551615 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_get_alignment=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_put_limit=18446744073709551615 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_put_alignment=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_max_send_size=16384 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_rdma_pipeline_send_length=2147483647 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_rdma_pipeline_frag_size=2147483647 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_min_rdma_pipeline_size=2147484671 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_latency=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_self_bandwidth=100 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_bandwidth_eth0=40000 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_latency_eth0=100 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_bandwidth_eth0:0=40000 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl_tcp_latency_eth0:0=100 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_base_bsend_allocator=basic (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_verbose=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_free_list_num=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_free_list_max=-1 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_free_list_inc=64 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_priority=20 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_send_pipeline_depth=3 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_recv_pipeline_depth=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_max_rdma_per_request=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_max_send_per_range=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_unexpected_limit=128 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_use_all_rdma=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] pml_ob1_allocator=bucket (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_priority=30 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_init_tree_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_init_chain_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_alltoall_small_msg=200 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_alltoall_intermediate_msg=3000 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_use_dynamic_rules=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_dynamic_rules_filename= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allreduce_algorithm_count=6 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allreduce_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allreduce_algorithm_segmentsize=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allreduce_algorithm_tree_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allreduce_algorithm_chain_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_alltoall_algorithm_count=6 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_alltoall_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_alltoall_algorithm_segmentsize=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_alltoall_algorithm_tree_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_alltoall_algorithm_chain_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_alltoall_algorithm_max_requests=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allgather_algorithm_count=7 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allgather_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allgather_algorithm_segmentsize=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allgather_algorithm_tree_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allgather_algorithm_chain_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allgatherv_algorithm_count=6 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allgatherv_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allgatherv_algorithm_segmentsize=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allgatherv_algorithm_tree_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_allgatherv_algorithm_chain_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_alltoallv_algorithm_count=3 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_alltoallv_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_barrier_algorithm_count=7 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_barrier_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_bcast_algorithm_count=7 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_bcast_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_bcast_algorithm_segmentsize=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_bcast_algorithm_tree_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_bcast_algorithm_chain_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_algorithm_count=7 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_algorithm_segmentsize=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_algorithm_tree_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_algorithm_chain_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_algorithm_max_requests=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_scatter_algorithm_count=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_scatter_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_scatter_algorithm_segmentsize=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_scatter_algorithm_tree_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_reduce_scatter_algorithm_chain_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_gather_algorithm_count=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_gather_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_gather_algorithm_segmentsize=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_gather_algorithm_tree_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_gather_algorithm_chain_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_scatter_algorithm_count=3 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_scatter_algorithm=ignore (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_scatter_algorithm_segmentsize=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_scatter_algorithm_tree_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_tuned_scatter_algorithm_chain_fanout=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sync_priority=50 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sync_barrier_before=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sync_barrier_after=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sm_priority=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sm_control_size=4096 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sm_fragment_size=8192 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sm_comm_in_use_flags=2 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sm_comm_num_segments=8 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sm_tree_degree=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sm_info_num_procs=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_sm_shared_mem_used_data=548864 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_inter_priority=40 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_inter_verbose=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_spacc_priority=5 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_spacc_verbose=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_libnbc_priority=10 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_libnbc_ibcast_skip_dt_decision=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_self_priority=75 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_basic_priority=10 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] coll_basic_crossover=4 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc= (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_base_verbose=error (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_no_locks=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_acc_single_intrinsic=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_acc_use_amo=true (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_buffer_size=32768 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_max_attach=32 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_aggregation_limit=0 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_priority=101 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_locking_mode=two_level (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_btls=openib,ugni,uct,ucp (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_mtls=psm2 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_rdma_backing_directory=/dev/shm (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_sm_backing_directory=/dev/shm (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_pt2pt_no_locks=false (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_pt2pt_buffer_size=8192 (default)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] osc_pt2pt_receive_count=4 (default)\n",
      "2021-10-13 04:03:25,449\tINFO scripts.py:620 -- Local node IP: 10.0.0.4\n",
      "2021-10-13 04:03:27,276\tINFO services.py:1265 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2021-10-13 04:03:27,279\tWARNING services.py:1759 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147483648 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.34gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2021-10-13 04:03:28,408\tSUCC scripts.py:659 -- --------------------\n",
      "2021-10-13 04:03:28,409\tSUCC scripts.py:660 -- Ray runtime started.\n",
      "2021-10-13 04:03:28,409\tSUCC scripts.py:661 -- --------------------\n",
      "2021-10-13 04:03:28,409\tINFO scripts.py:663 -- Next steps\n",
      "2021-10-13 04:03:28,409\tINFO scripts.py:665 -- To connect to this Ray runtime from another node, run\n",
      "2021-10-13 04:03:28,409\tINFO scripts.py:671 --   ray start --address='10.0.0.4:6379' --redis-password='5241590000000000'\n",
      "2021-10-13 04:03:28,409\tINFO scripts.py:673 -- Alternatively, use the following Python code:\n",
      "2021-10-13 04:03:28,410\tINFO scripts.py:676 -- import ray\n",
      "2021-10-13 04:03:28,410\tINFO scripts.py:683 -- ray.init(address='auto', _redis_password='5241590000000000')\n",
      "2021-10-13 04:03:28,410\tINFO scripts.py:685 -- To connect to this Ray runtime from outside of the cluster, for example to\n",
      "2021-10-13 04:03:28,410\tINFO scripts.py:687 -- connect to a remote cluster from your laptop directly, use the following\n",
      "2021-10-13 04:03:28,410\tINFO scripts.py:689 -- Python code:\n",
      "2021-10-13 04:03:28,410\tINFO scripts.py:692 -- import ray\n",
      "2021-10-13 04:03:28,410\tINFO scripts.py:696 -- ray.init(address='ray://<head_node_ip_address>:10001')\n",
      "2021-10-13 04:03:28,411\tINFO scripts.py:700 -- If connection fails, check your firewall settings and network configuration.\n",
      "2021-10-13 04:03:28,411\tINFO scripts.py:704 -- To terminate the Ray runtime, run\n",
      "2021-10-13 04:03:28,411\tINFO scripts.py:705 --   ray stop\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: path from 10.0.0.4 to 10.0.0.6: IPV4 PRIVATE SAME NETWORK\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: bml: Using tcp btl for send to [[55207,1],1] on node (null)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl: tcp: attempting to connect() to [[55207,1],1] address 10.0.0.6 on port 1024\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: would block, so allowing background progress\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: path from 10.0.0.4 to 10.0.0.9: IPV4 PRIVATE SAME NETWORK\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] mca: bml: Using tcp btl for send to [[55207,1],2] on node (null)\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl: tcp: attempting to connect() to [[55207,1],2] address 10.0.0.9 on port 1024\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: would block, so allowing background progress\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: connect() to 10.0.0.9:1024 completed (complete_connect), sending connect ACK\n",
      "[cd14b61fbfe54116be7b7b7e2f4f3ea4000000:00402] btl:tcp: connect() to 10.0.0.6:1024 completed (complete_connect), sending connect ACK\n",
      "2021-10-13 04:03:29,408\tINFO worker.py:826 -- Connecting to existing Ray cluster at address: 10.0.0.4:6379\n",
      "== Status ==\n",
      "Memory usage on this node: 1.9/13.7 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/26.31 GiB heap, 0.0/11.84 GiB objects\n",
      "Result logdir: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/minecraft_rl_test_1634097472_c2a1da1f/wd/azureml/minecraft_rl_test_1634097472_c2a1da1f/outputs/IMPALA\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "+-----------------------------------------------------+----------+-------+\n",
      "| Trial name                                          | status   | loc   |\n",
      "|-----------------------------------------------------+----------+-------|\n",
      "| IMPALA_custom_malmo_env:MalmoMazeEnv-v0_887c0_00000 | PENDING  |       |\n",
      "+-----------------------------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=568)\u001b[0m 2021-10-13 04:03:38,505\tINFO trainer.py:714 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=568)\u001b[0m 2021-10-13 04:03:38,505\tWARNING deprecation.py:39 -- DeprecationWarning: `callbacks dict interface` has been deprecated. Use `a class extending rllib.agents.callbacks.DefaultCallbacks` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=568)\u001b[0m 2021-10-13 04:03:38,505\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=454, ip=10.0.0.9)\u001b[0m Waiting Minecraft instance to start ...\n",
      "\u001b[2m\u001b[36m(pid=454, ip=10.0.0.9)\u001b[0m 2021-10-13 04:03:43,013\tWARNING deprecation.py:39 -- DeprecationWarning: `callbacks dict interface` has been deprecated. Use `a class extending rllib.agents.callbacks.DefaultCallbacks` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=452, ip=10.0.0.6)\u001b[0m 2021-10-13 04:03:43,196\tWARNING deprecation.py:39 -- DeprecationWarning: `callbacks dict interface` has been deprecated. Use `a class extending rllib.agents.callbacks.DefaultCallbacks` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=452, ip=10.0.0.6)\u001b[0m Waiting Minecraft instance to start ...\n",
      "\u001b[2m\u001b[36m(pid=597)\u001b[0m Waiting Minecraft instance to start ...\n",
      "\u001b[2m\u001b[36m(pid=597)\u001b[0m 2021-10-13 04:03:43,511\tWARNING deprecation.py:39 -- DeprecationWarning: `callbacks dict interface` has been deprecated. Use `a class extending rllib.agents.callbacks.DefaultCallbacks` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=454, ip=10.0.0.9)\u001b[0m Finished waiting for instance\n",
      "\u001b[2m\u001b[36m(pid=454, ip=10.0.0.9)\u001b[0m 2021-10-13 04:07:08,541\tWARNING deprecation.py:39 -- DeprecationWarning: `callbacks dict interface` has been deprecated. Use `a class extending rllib.agents.callbacks.DefaultCallbacks` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=568)\u001b[0m 2021-10-13 04:07:09,850\tWARNING deprecation.py:39 -- DeprecationWarning: `callbacks dict interface` has been deprecated. Use `a class extending rllib.agents.callbacks.DefaultCallbacks` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=568)\u001b[0m 2021-10-13 04:07:10,222\tWARNING deprecation.py:39 -- DeprecationWarning: `callbacks dict interface` has been deprecated. Use `a class extending rllib.agents.callbacks.DefaultCallbacks` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=568)\u001b[0m 2021-10-13 04:07:11,897\tINFO trainable.py:109 -- Trainable.setup took 213.393 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=568)\u001b[0m 2021-10-13 04:07:11,898\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=452, ip=10.0.0.6)\u001b[0m Finished waiting for instance\n",
      "\u001b[2m\u001b[36m(pid=452, ip=10.0.0.6)\u001b[0m 2021-10-13 04:07:13,720\tWARNING deprecation.py:39 -- DeprecationWarning: `callbacks dict interface` has been deprecated. Use `a class extending rllib.agents.callbacks.DefaultCallbacks` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=597)\u001b[0m Finished waiting for instance\n",
      "\u001b[2m\u001b[36m(pid=597)\u001b[0m 2021-10-13 04:07:19,077\tWARNING deprecation.py:39 -- DeprecationWarning: `callbacks dict interface` has been deprecated. Use `a class extending rllib.agents.callbacks.DefaultCallbacks` instead. This will raise an error in the future!\n",
      "Result for IMPALA_custom_malmo_env:MalmoMazeEnv-v0_887c0_00000:\n",
      "  agent_timesteps_total: 500\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_04-10-44\n",
      "  done: false\n",
      "  episode_len_mean: 5.102564102564102\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -104.4551282051282\n",
      "  episode_reward_min: -128.0\n",
      "  episodes_this_iter: 156\n",
      "  episodes_total: 156\n",
      "  experiment_id: e42db0f41ca44a67b6849af2b138aec9\n",
      "  hostname: cd14b61fbfe54116be7b7b7e2f4f3ea4000000\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.13840879499912262\n",
      "        entropy_coeff: 0.009999999776482582\n",
      "        grad_gnorm: 40.000003814697266\n",
      "        model: {}\n",
      "        policy_loss: -1.4073392152786255\n",
      "        var_gnorm: 9.427295684814453\n",
      "        vf_explained_var: -0.0005112886428833008\n",
      "        vf_loss: 133.38641357421875\n",
      "    learner_queue:\n",
      "      size_count: 1\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_agent_steps_sampled: 500\n",
      "    num_steps_sampled: 500\n",
      "    num_steps_trained: 500\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 149319.753\n",
      "      learner_grad_time_ms: 1889.51\n",
      "      learner_load_time_ms: 0.013\n",
      "      learner_load_wait_time_ms: 149247.467\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.4\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.87565789473685\n",
      "    ram_util_percent: 38.50822368421053\n",
      "  pid: 568\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11342051968003523\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 180.19847611549818\n",
      "    mean_inference_ms: 3.2758010889836693\n",
      "    mean_raw_obs_processing_ms: 533.6470720644205\n",
      "  time_since_restore: 212.43070578575134\n",
      "  time_this_iter_s: 212.43070578575134\n",
      "  time_total_s: 212.43070578575134\n",
      "  timers:\n",
      "    sample_throughput: 3.351\n",
      "    sample_time_ms: 149221.701\n",
      "  timestamp: 1634098244\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 500\n",
      "  training_iteration: 1\n",
      "  trial_id: 887c0_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 5.4/13.7 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 10.0/12 CPUs, 0/0 GPUs, 0.0/26.31 GiB heap, 0.0/11.84 GiB objects\n",
      "Result logdir: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/minecraft_rl_test_1634097472_c2a1da1f/wd/azureml/minecraft_rl_test_1634097472_c2a1da1f/outputs/IMPALA\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------------------+----------+--------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                                          | status   | loc          |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------------------+----------+--------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_custom_malmo_env:MalmoMazeEnv-v0_887c0_00000 | RUNNING  | 10.0.0.4:568 |      1 |          212.431 |  500 | -104.455 |                    0 |                 -128 |            5.10256 |\n",
      "+-----------------------------------------------------+----------+--------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for IMPALA_custom_malmo_env:MalmoMazeEnv-v0_887c0_00000:\n",
      "  agent_timesteps_total: 1000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_04-13-05\n",
      "  done: false\n",
      "  episode_len_mean: 4.2727272727272725\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -101.0\n",
      "  episode_reward_mean: -104.27272727272727\n",
      "  episode_reward_min: -119.0\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 266\n",
      "  experiment_id: e42db0f41ca44a67b6849af2b138aec9\n",
      "  hostname: cd14b61fbfe54116be7b7b7e2f4f3ea4000000\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.0\n",
      "        entropy_coeff: 0.009999999776482582\n",
      "        grad_gnorm: 40.000003814697266\n",
      "        model: {}\n",
      "        policy_loss: -0.0\n",
      "        var_gnorm: 9.436050415039062\n",
      "        vf_explained_var: 0.02235853672027588\n",
      "        vf_loss: 0.4523555636405945\n",
      "    learner_queue:\n",
      "      size_count: 2\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 1000\n",
      "    num_weight_broadcasts: 1\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 149319.753\n",
      "      learner_grad_time_ms: 1708.35\n",
      "      learner_load_time_ms: 0.013\n",
      "      learner_load_wait_time_ms: 138917.884\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 10.0.0.4\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.28049999999999\n",
      "    ram_util_percent: 40.037\n",
      "  pid: 568\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10790207272681467\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 150.27992451444229\n",
      "    mean_inference_ms: 3.121025287950479\n",
      "    mean_raw_obs_processing_ms: 536.7924425409404\n",
      "  time_since_restore: 352.9593434333801\n",
      "  time_this_iter_s: 140.52863764762878\n",
      "  time_total_s: 352.9593434333801\n",
      "  timers:\n",
      "    sample_throughput: 3.576\n",
      "    sample_time_ms: 139839.878\n",
      "  timestamp: 1634098385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 2\n",
      "  trial_id: 887c0_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 5.5/13.7 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 10.0/12 CPUs, 0/0 GPUs, 0.0/26.31 GiB heap, 0.0/11.84 GiB objects\n",
      "Result logdir: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/minecraft_rl_test_1634097472_c2a1da1f/wd/azureml/minecraft_rl_test_1634097472_c2a1da1f/outputs/IMPALA\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------------------+----------+--------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                                          | status   | loc          |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------------------+----------+--------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_custom_malmo_env:MalmoMazeEnv-v0_887c0_00000 | RUNNING  | 10.0.0.4:568 |      2 |          352.959 | 1000 | -104.273 |                 -101 |                 -119 |            4.27273 |\n",
      "+-----------------------------------------------------+----------+--------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_custom_malmo_env:MalmoMazeEnv-v0_887c0_00000:\n",
      "  agent_timesteps_total: 1500\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_04-15-03\n",
      "  done: false\n",
      "  episode_len_mean: 5.098039215686274\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -101.0\n",
      "  episode_reward_mean: -105.09803921568627\n",
      "  episode_reward_min: -126.0\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 368\n",
      "  experiment_id: e42db0f41ca44a67b6849af2b138aec9\n",
      "  hostname: cd14b61fbfe54116be7b7b7e2f4f3ea4000000\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.0\n",
      "        entropy_coeff: 0.009999999776482582\n",
      "        grad_gnorm: 40.0\n",
      "        model: {}\n",
      "        policy_loss: -0.0\n",
      "        var_gnorm: 9.450931549072266\n",
      "        vf_explained_var: 0.04075777530670166\n",
      "        vf_loss: 0.569044828414917\n",
      "    learner_queue:\n",
      "      size_count: 3\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_agent_steps_sampled: 1500\n",
      "    num_steps_sampled: 1500\n",
      "    num_steps_trained: 1500\n",
      "    num_weight_broadcasts: 2\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 149319.753\n",
      "      learner_grad_time_ms: 1627.241\n",
      "      learner_load_time_ms: 0.013\n",
      "      learner_load_wait_time_ms: 133435.682\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.0.0.4\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.098214285714285\n",
      "    ram_util_percent: 40.72440476190476\n",
      "  pid: 568\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10495145291556231\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 136.86143764653139\n",
      "    mean_inference_ms: 3.040664601242095\n",
      "    mean_raw_obs_processing_ms: 542.4445531249033\n",
      "  time_since_restore: 470.83913683891296\n",
      "  time_this_iter_s: 117.87979340553284\n",
      "  time_total_s: 470.83913683891296\n",
      "  timers:\n",
      "    sample_throughput: 3.716\n",
      "    sample_time_ms: 134552.616\n",
      "  timestamp: 1634098503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1500\n",
      "  training_iteration: 3\n",
      "  trial_id: 887c0_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 5.6/13.7 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 10.0/12 CPUs, 0/0 GPUs, 0.0/26.31 GiB heap, 0.0/11.84 GiB objects\n",
      "Result logdir: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/minecraft_rl_test_1634097472_c2a1da1f/wd/azureml/minecraft_rl_test_1634097472_c2a1da1f/outputs/IMPALA\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------------------+----------+--------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                                          | status   | loc          |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------------------+----------+--------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_custom_malmo_env:MalmoMazeEnv-v0_887c0_00000 | RUNNING  | 10.0.0.4:568 |      3 |          470.839 | 1500 | -105.098 |                 -101 |                 -126 |            5.09804 |\n",
      "+-----------------------------------------------------+----------+--------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name='minecraft_rl_test')\n",
    "run = exp.submit(config=src)\n",
    "# See the output when debugging\n",
    "# run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Remove cluster (Clean-up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cluster (nodes) in AML workspace\n",
    "mycompute = AmlCompute(workspace=ws, name='cluster01')\n",
    "mycompute.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
