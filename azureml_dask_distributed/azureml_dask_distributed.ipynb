{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Dask Distribution in Azure Machine Learning\n",
    "\n",
    "In this notebook, we run Dask distributed training in Azure Machine Learning.<br>\n",
    "When the training has completed, the computing instances will automatically be scaled down to 0 instances.\n",
    "\n",
    "To run this notebook,\n",
    "\n",
    "1. Create new \"Machine Learning\" resource in [Azure Portal](https://portal.azure.com/).\n",
    "2. Install Azure Machine Learning CLI v2 on Ubuntu as follows\n",
    "\n",
    "```\n",
    "# install Azure CLI\n",
    "curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n",
    "# install AML CLI extension\n",
    "az extension add --name ml\n",
    "```\n",
    "\n",
    "Here I use built-in Dask ML function (```dask_ml.linear_model.LinearRegression```) in this tutorial, but you can run **a variety of scikit-learn compliant functions and jobs** in distributed manners with Dask cluster.<br>\n",
    "For dask distribution, see \"[Run Distributed Dask on Azure Kubernetes Service](https://tsmatz.wordpress.com/2021/05/17/dask-distributed-on-azure-kubernetes/)\" for details.\n",
    "\n",
    "> Note : You can now also use Python package ```ray-on-aml``` for running dask on ray in Azure Machine Learning computes. (See [here](https://github.com/microsoft/ray-on-aml).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Python script for Distributed Dask training (Regression Example)\n",
    "\n",
    "Create a directory for saving your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a script file (```dask_distributed_example.py```) for Distributed Dask training.<br>\n",
    "Here we run 4 nodes with the following roles.\n",
    "\n",
    "- Rank 0 : Dask Scheduler\n",
    "- Rank 1 : Dask Worker\n",
    "- Rank 2 : Dask Worker\n",
    "- Rank 3 : Dask Client\n",
    "\n",
    "Here I create Python script for each 3 roles as follows.\n",
    "\n",
    "In this example, we only output the evaluation score in the console, but you can also save the generated model as AML outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/dask_scheduler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/dask_scheduler.py\n",
    "import argparse\n",
    "import asyncio\n",
    "from dask.distributed import Scheduler\n",
    "import mpi4py\n",
    "from mpi4py import MPI\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--node_count\",\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help=\"number of nodes\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "mpi_comm = MPI.COMM_WORLD\n",
    "mpi_rank = mpi_comm.Get_rank()\n",
    "\n",
    "async def f_scheduler():\n",
    "    # Send ready message to client\n",
    "    req = mpi_comm.isend('ready', dest=args.node_count-1, tag=mpi_rank)\n",
    "    req.wait()\n",
    "    # Start scheduler\n",
    "    s = Scheduler(port=8786)\n",
    "    # Wait requests\n",
    "    s = await s\n",
    "    # Finalize\n",
    "    await s.finished()\n",
    "asyncio.get_event_loop().run_until_complete(f_scheduler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/dask_worker.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/dask_worker.py\n",
    "import argparse\n",
    "import asyncio\n",
    "from dask.distributed import Worker\n",
    "import mpi4py\n",
    "from mpi4py import MPI\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--scheduler_address\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"dask scheduler address\")\n",
    "parser.add_argument(\"--node_count\",\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help=\"number of nodes\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "mpi_comm = MPI.COMM_WORLD\n",
    "mpi_rank = mpi_comm.Get_rank()\n",
    "\n",
    "async def f_worker(scheduler_address):\n",
    "    # Send ready message to client\n",
    "    req = mpi_comm.isend('ready', dest=args.node_count-1, tag=mpi_rank)\n",
    "    req.wait()\n",
    "    # Start Worker\n",
    "    w = await Worker(scheduler_address)\n",
    "    # Wait for worker's complete\n",
    "    await w.finished()\n",
    "asyncio.get_event_loop().run_until_complete(f_worker(args.scheduler_address))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/dask_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/dask_client.py\n",
    "import argparse\n",
    "import asyncio\n",
    "import time\n",
    "from dask.distributed import Client\n",
    "from dask_ml.datasets import make_regression\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "import mpi4py\n",
    "from mpi4py import MPI\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--scheduler_address\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"dask scheduler address\")\n",
    "parser.add_argument(\"--node_count\",\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help=\"number of nodes\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Wait for all server's ready message\n",
    "mpi_comm = MPI.COMM_WORLD\n",
    "mpi_rank = mpi_comm.Get_rank()\n",
    "for n in range(args.node_count - 1):\n",
    "    req = mpi_comm.irecv(source=n, tag=n)\n",
    "    data = req.wait()\n",
    "\n",
    "# Create client\n",
    "time.sleep(3)\n",
    "c = Client(args.scheduler_address)\n",
    "\n",
    "# Run program !\n",
    "X, y = make_regression(\n",
    "  n_samples=100000,\n",
    "  n_features=4,\n",
    "  chunks=50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('##### Trained Model Result #####')\n",
    "print('Score : {}'.format(lr.score(X_test, y_test)))\n",
    "\n",
    "# simple test\n",
    "# y = c.submit(lambda x: x + 1, 10)\n",
    "# print('The result is {}'.format(y.result()))\n",
    "\n",
    "# Stop scheduler and wokers\n",
    "c.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create shell script to run each role\n",
    "\n",
    "Create shell script for running each roles and starting training in Dask distribution job.\n",
    "\n",
    "> Note : See [here](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-distributed-gpu) for environment variables in AML distributed cluster.<br>\n",
    "> The following ```$AZ_BATCHAI_MPI_MASTER_NODE``` is an environment variable for MPI master's host name (such as, ```10.5.0.4```). You can also use the following shell command to retreive master's host name.<br>\n",
    "> ```cut -d \":\" -f 1 <<< $AZ_BATCH_MASTER_NODE```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/run.sh\n",
    "if [ $OMPI_COMM_WORLD_RANK -eq 0 ]\n",
    "then\n",
    "    echo \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n",
    "    echo \"Dask Scheduler\"\n",
    "    echo \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n",
    "    python dask_scheduler.py --node_count $OMPI_COMM_WORLD_SIZE\n",
    "elif [ $OMPI_COMM_WORLD_RANK -eq $((OMPI_COMM_WORLD_SIZE-1)) ]\n",
    "then\n",
    "    echo \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n",
    "    echo \"Dask Client\"\n",
    "    echo \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n",
    "    python dask_client.py --scheduler_address $AZ_BATCHAI_MPI_MASTER_NODE:8786 --node_count $OMPI_COMM_WORLD_SIZE\n",
    "else\n",
    "    echo \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n",
    "    echo \"Dask Worker\"\n",
    "    echo \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n",
    "    python dask_worker.py --scheduler_address $AZ_BATCHAI_MPI_MASTER_NODE:8786 --node_count $OMPI_COMM_WORLD_SIZE\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submit Job in Azure Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for connecting to Azure Machine Learning workspace\n",
    "\n",
    "Login to Azure and prepare for connecting to Azure Machine Learning (AML) workspace.<br>\n",
    "Please fill the following subscription id, AML workspace name, and resource group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s {AZURE_SUBSCRIPTION_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resource_group = \"{AML_RESOURCE_GROUP_NAME}\"\n",
    "my_workspace = \"{AML_WORSPACE_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cluster (multiple nodes)\n",
    "\n",
    "Create a remote cluster with 4 nodes - 1 scheduler, 2 workers, and 1 client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/computes/cluster01\",\r\n",
      "  \"idle_time_before_scale_down\": 120,\r\n",
      "  \"location\": \"eastus\",\r\n",
      "  \"max_instances\": 4,\r\n",
      "  \"min_instances\": 0,\r\n",
      "  \"name\": \"cluster01\",\r\n",
      "  \"network_settings\": {},\r\n",
      "  \"provisioning_state\": \"Succeeded\",\r\n",
      "  \"resourceGroup\": \"rg-AML\",\r\n",
      "  \"size\": \"STANDARD_DS2_V2\",\r\n",
      "  \"ssh_public_access_enabled\": true,\r\n",
      "  \"tier\": \"dedicated\",\r\n",
      "  \"type\": \"amlcompute\"\r\n",
      "}\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute create --name cluster01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --type amlcompute \\\n",
    "  --min-instances 0 \\\n",
    "  --max-instances 4 \\\n",
    "  --size Standard_DS2_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AML environment for dask distribution \n",
    "\n",
    "Now we prepare custom environment to run dask distribution job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conda_dask_distribution.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda_dask_distribution.yml\n",
    "name: dask_environment\n",
    "dependencies:\n",
    "- python=3.8\n",
    "- pip:\n",
    "  - mpi4py\n",
    "  - dask\n",
    "  - distributed\n",
    "  - dask-ml\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing env_dask_distribution.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile env_dask_distribution.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json\n",
    "name: dask-distribution-env\n",
    "image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\n",
    "conda_file: conda_dask_distribution.yml\n",
    "description: environment for dask distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"conda_file\": {\n",
      "    \"channels\": [\n",
      "      \"anaconda\",\n",
      "      \"conda-forge\"\n",
      "    ],\n",
      "    \"dependencies\": [\n",
      "      \"python=3.8\",\n",
      "      {\n",
      "        \"pip\": [\n",
      "          \"mpi4py\",\n",
      "          \"dask\",\n",
      "          \"distributed\",\n",
      "          \"dask-ml\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"name\": \"dask_environment\"\n",
      "  },\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-08-25T08:36:50.303293+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2022-08-25T08:36:50.303293+00:00\",\n",
      "    \"last_modified_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"environment for dask distribution\",\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/environments/dask-distribution-env/versions/1\",\n",
      "  \"image\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
      "  \"name\": \"dask-distribution-env\",\n",
      "  \"os_type\": \"linux\",\n",
      "  \"resourceGroup\": \"rg-AML\",\n",
      "  \"tags\": {},\n",
      "  \"version\": \"1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml environment create --file env_dask_distribution.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Job\n",
    "\n",
    "Now let's run dask distributed job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_dask_distribution.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_dask_distribution.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "code: script\n",
    "command: bash run.sh\n",
    "environment: azureml:dask-distribution-env@latest\n",
    "compute: azureml:cluster01\n",
    "display_name: dask_dist_test\n",
    "experiment_name: dask_dist_test\n",
    "resources:\n",
    "  instance_count: 4\n",
    "distribution:\n",
    "  type: mpi\n",
    "  process_count_per_instance: 1\n",
    "description: Dask distribution job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading script (0.0 MBs): 100%|█████████| 3494/3494 [00:01<00:00, 3408.26it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"code\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/codes/effc4de9-bd46-4f4d-b6e1-9f38102180d8/versions/1\",\n",
      "  \"command\": \"bash run.sh\",\n",
      "  \"compute\": \"azureml:cluster01\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-08-25T08:37:23.564101+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"Dask distribution job\",\n",
      "  \"display_name\": \"dask_dist_test\",\n",
      "  \"distribution\": {\n",
      "    \"process_count_per_instance\": 1,\n",
      "    \"type\": \"mpi\"\n",
      "  },\n",
      "  \"environment\": \"azureml:dask-distribution-env:1\",\n",
      "  \"environment_variables\": {},\n",
      "  \"experiment_name\": \"dask_dist_test\",\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/cool_feather_zpcjfq8pqw\",\n",
      "  \"inputs\": {},\n",
      "  \"name\": \"cool_feather_zpcjfq8pqw\",\n",
      "  \"outputs\": {\n",
      "    \"default\": {\n",
      "      \"mode\": \"rw_mount\",\n",
      "      \"path\": \"azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.cool_feather_zpcjfq8pqw\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"parameters\": {},\n",
      "  \"properties\": {\n",
      "    \"ContentSnapshotId\": \"ad06e1e1-642d-4803-807b-ce27ab32408c\",\n",
      "    \"_azureml.ComputeTargetType\": \"amlctrain\",\n",
      "    \"azureml.git.dirty\": \"True\",\n",
      "    \"mlflow.source.git.branch\": \"master\",\n",
      "    \"mlflow.source.git.commit\": \"c35fff0fc96a73f511b370e8f39bb90dca761282\",\n",
      "    \"mlflow.source.git.repoURL\": \"https://github.com/tsmatz/azureml-examples\"\n",
      "  },\n",
      "  \"resourceGroup\": \"rg-AML\",\n",
      "  \"resources\": {\n",
      "    \"instance_count\": 4,\n",
      "    \"properties\": {}\n",
      "  },\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/cool_feather_zpcjfq8pqw?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/rg-AML/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "      \"job_service_type\": \"Studio\"\n",
      "    },\n",
      "    \"Tracking\": {\n",
      "      \"endpoint\": \"azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01?\",\n",
      "      \"job_service_type\": \"Tracking\"\n",
      "    }\n",
      "  },\n",
      "  \"status\": \"Starting\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"command\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job create --file train_dask_distribution.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the output results in [Azure Machine Learning studio](https://ml.azure.com/).\n",
    "\n",
    "![AML outputs](./output_artifact.jpg)\n",
    "\n",
    "You can download all logs and outputs in local folder and analyze.<br>\n",
    "Now, let's check the output results in rank 3 (dask client)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"{FILL_JOB_NAME}\"\n",
    "# Example : job_name = \"cool_feather_zpcjfq8pqw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading artifact azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.cool_feather_zpcjfq8pqw to dask_training_result/artifacts\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job download --name $job_name \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --download-path dask_training_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: Attempting to bind to AF_INET port 1024\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: Successfully bound to AF_INET port 1024\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: my listening v4 socket is 0.0.0.0:1024\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: examining interface eth0\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: using ipv6 interface eth0\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] select: init of component tcp returned success\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] select: initializing btl component vader\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] select: init of component vader returned failure\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] mca: base: close: component vader closed\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] mca: base: close: unloading component vader\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] select: initializing btl component self\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] select: init of component self returned success\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] mca: bml: Using self btl for send to [[7785,1],3] on node 21281da39c3740c6888b333530768964000004\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: path from 10.0.0.8 to 10.0.0.5: IPV4 PRIVATE SAME NETWORK\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: now connected to 10.0.0.5, process [[7785,1],0]\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: path from 10.0.0.8 to 10.0.0.6: IPV4 PRIVATE SAME NETWORK\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: now connected to 10.0.0.6, process [[7785,1],1]\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: path from 10.0.0.8 to 10.0.0.7: IPV4 PRIVATE SAME NETWORK\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] btl:tcp: now connected to 10.0.0.7, process [[7785,1],2]\r\n",
      "##### Trained Model Result #####\r\n",
      "Score : 0.9999999997175051\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] mca: base: close: component tcp closed\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] mca: base: close: unloading component tcp\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] mca: base: close: component self closed\r\n",
      "[21281da39c3740c6888b333530768964000004:00130] mca: base: close: unloading component self\r\n",
      "[2022-08-25T08:55:07.625995] Command finished with exit code 0 interpreted as return code 0\r\n",
      "\r\n",
      "\r\n",
      "[2022-08-25T08:55:07.626344] The experiment completed successfully. Finalizing run...\r\n",
      "[2022-08-25T08:55:07.626502] Finished context manager injector.\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 30 dask_training_result/artifacts/azureml-logs/70_driver_log_3.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean-up (Remove cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml compute delete --name cluster01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
