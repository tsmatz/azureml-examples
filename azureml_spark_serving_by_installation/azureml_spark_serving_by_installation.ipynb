{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark ML serving in Azure Machine Learning (by Spark installation)\n",
    "\n",
    "In this notebook, I'll host (install) single instance of Apache Spark and provide Spark ML inference by running pyspark on Azure Machine Learning online endpoint.\n",
    "\n",
    "To run this notebook,\n",
    "\n",
    "1. Create new \"Machine Learning\" resource in [Azure Portal](https://portal.azure.com/).\n",
    "2. Install Azure Machine Learning CLI v2 on Ubuntu as follows\n",
    "\n",
    "```\n",
    "# install Azure CLI\n",
    "curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n",
    "# install AML CLI extension\n",
    "az extension add --name ml\n",
    "```\n",
    "\n",
    "> Note : See [here](https://tsmatz.wordpress.com/2019/03/04/spark-ml-pipeline-serving-inference-by-azure-machine-learning-service/) for other deployment options for Spark ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Azure Machine Learning workspace\n",
    "\n",
    "Login to Azure and prepare for connecting to Azure Machine Learning (AML) workspace.<br>\n",
    "Please fill the following subscription id, AML workspace name, and resource group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s {AZURE_SUBSCRIPTION_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resource_group = \"{AML_RESOURCE_GROUP_NAME}\"\n",
    "my_workspace = \"{AML_WORSPACE_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and register into AML\n",
    "\n",
    "In this example, we use Spark ML pipeline model, ```flight_model```, which is trained in [this Databricks exercise](https://tsmatz.github.io/azure-databricks-exercise/exercise03-sparkml-pipeline.html).<br>\n",
    "This pipeline uses inputs for flight and weather information (such as, aircraft carrier, depature/arrival time, depature/arrival wind speed, depature/arrival visibility, etc) and then predicts flight arrival's delay over 15 minutes by 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpack ```flight_model.zip``` in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  flight_model.zip\r\n",
      "   creating: flight_model/\r\n",
      "   creating: flight_model/metadata/\r\n",
      "  inflating: flight_model/metadata/part-00000  \r\n",
      " extracting: flight_model/metadata/_SUCCESS  \r\n",
      "   creating: flight_model/stages/\r\n",
      "   creating: flight_model/stages/5_DecisionTreeClassifier_a1f5c7b0f6f3/\r\n",
      "   creating: flight_model/stages/5_DecisionTreeClassifier_a1f5c7b0f6f3/metadata/\r\n",
      "  inflating: flight_model/stages/5_DecisionTreeClassifier_a1f5c7b0f6f3/metadata/part-00000  \r\n",
      " extracting: flight_model/stages/5_DecisionTreeClassifier_a1f5c7b0f6f3/metadata/_SUCCESS  \r\n",
      "   creating: flight_model/stages/5_DecisionTreeClassifier_a1f5c7b0f6f3/data/\r\n",
      "  inflating: flight_model/stages/5_DecisionTreeClassifier_a1f5c7b0f6f3/data/_committed_3287493269964804398  \r\n",
      "  inflating: flight_model/stages/5_DecisionTreeClassifier_a1f5c7b0f6f3/data/part-00000-tid-3287493269964804398-cb7b99f7-874c-429d-a3b2-4d2bd2a6d998-374-1-c000.snappy.parquet  \r\n",
      " extracting: flight_model/stages/5_DecisionTreeClassifier_a1f5c7b0f6f3/data/_SUCCESS  \r\n",
      " extracting: flight_model/stages/5_DecisionTreeClassifier_a1f5c7b0f6f3/data/_started_3287493269964804398  \r\n",
      "   creating: flight_model/stages/3_StringIndexer_b2af38910a56/\r\n",
      "   creating: flight_model/stages/3_StringIndexer_b2af38910a56/metadata/\r\n",
      "  inflating: flight_model/stages/3_StringIndexer_b2af38910a56/metadata/part-00000  \r\n",
      " extracting: flight_model/stages/3_StringIndexer_b2af38910a56/metadata/_SUCCESS  \r\n",
      "   creating: flight_model/stages/3_StringIndexer_b2af38910a56/data/\r\n",
      "  inflating: flight_model/stages/3_StringIndexer_b2af38910a56/data/_committed_8566640864128032782  \r\n",
      "  inflating: flight_model/stages/3_StringIndexer_b2af38910a56/data/part-00000-tid-8566640864128032782-eef53f96-a1e8-4697-bfc2-35550dc55f4d-363-1-c000.snappy.parquet  \r\n",
      " extracting: flight_model/stages/3_StringIndexer_b2af38910a56/data/_started_8566640864128032782  \r\n",
      " extracting: flight_model/stages/3_StringIndexer_b2af38910a56/data/_SUCCESS  \r\n",
      "   creating: flight_model/stages/1_StringIndexer_9d7d804b1075/\r\n",
      "   creating: flight_model/stages/1_StringIndexer_9d7d804b1075/metadata/\r\n",
      "  inflating: flight_model/stages/1_StringIndexer_9d7d804b1075/metadata/part-00000  \r\n",
      " extracting: flight_model/stages/1_StringIndexer_9d7d804b1075/metadata/_SUCCESS  \r\n",
      "   creating: flight_model/stages/1_StringIndexer_9d7d804b1075/data/\r\n",
      "  inflating: flight_model/stages/1_StringIndexer_9d7d804b1075/data/_committed_8225874192090561642  \r\n",
      "  inflating: flight_model/stages/1_StringIndexer_9d7d804b1075/data/part-00000-tid-8225874192090561642-b776892e-7199-467f-8ad4-2d4aac26aa92-357-1-c000.snappy.parquet  \r\n",
      " extracting: flight_model/stages/1_StringIndexer_9d7d804b1075/data/_started_8225874192090561642  \r\n",
      " extracting: flight_model/stages/1_StringIndexer_9d7d804b1075/data/_SUCCESS  \r\n",
      "   creating: flight_model/stages/4_VectorAssembler_94e41a97ea8d/\r\n",
      "   creating: flight_model/stages/4_VectorAssembler_94e41a97ea8d/metadata/\r\n",
      "  inflating: flight_model/stages/4_VectorAssembler_94e41a97ea8d/metadata/part-00000  \r\n",
      " extracting: flight_model/stages/4_VectorAssembler_94e41a97ea8d/metadata/_SUCCESS  \r\n",
      "   creating: flight_model/stages/2_StringIndexer_2a911c0fc6d1/\r\n",
      "   creating: flight_model/stages/2_StringIndexer_2a911c0fc6d1/metadata/\r\n",
      "  inflating: flight_model/stages/2_StringIndexer_2a911c0fc6d1/metadata/part-00000  \r\n",
      " extracting: flight_model/stages/2_StringIndexer_2a911c0fc6d1/metadata/_SUCCESS  \r\n",
      "   creating: flight_model/stages/2_StringIndexer_2a911c0fc6d1/data/\r\n",
      " extracting: flight_model/stages/2_StringIndexer_2a911c0fc6d1/data/_started_5823213892383154323  \r\n",
      "  inflating: flight_model/stages/2_StringIndexer_2a911c0fc6d1/data/_committed_5823213892383154323  \r\n",
      "  inflating: flight_model/stages/2_StringIndexer_2a911c0fc6d1/data/part-00000-tid-5823213892383154323-2f578cb3-fd07-4021-8f1a-5fa7593a9f9d-360-1-c000.snappy.parquet  \r\n",
      " extracting: flight_model/stages/2_StringIndexer_2a911c0fc6d1/data/_SUCCESS  \r\n",
      "   creating: flight_model/stages/0_StringIndexer_0e115d8fabc9/\r\n",
      "   creating: flight_model/stages/0_StringIndexer_0e115d8fabc9/metadata/\r\n",
      "  inflating: flight_model/stages/0_StringIndexer_0e115d8fabc9/metadata/part-00000  \r\n",
      " extracting: flight_model/stages/0_StringIndexer_0e115d8fabc9/metadata/_SUCCESS  \r\n",
      "   creating: flight_model/stages/0_StringIndexer_0e115d8fabc9/data/\r\n",
      " extracting: flight_model/stages/0_StringIndexer_0e115d8fabc9/data/_started_6702294294392278852  \r\n",
      "  inflating: flight_model/stages/0_StringIndexer_0e115d8fabc9/data/_committed_6702294294392278852  \r\n",
      "  inflating: flight_model/stages/0_StringIndexer_0e115d8fabc9/data/part-00000-tid-6702294294392278852-857b601a-76f7-4cb7-bd24-f809b4e54cfb-354-1-c000.snappy.parquet  \r\n",
      " extracting: flight_model/stages/0_StringIndexer_0e115d8fabc9/data/_SUCCESS  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip flight_model.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we register this trained Spark MLlib model into Azure Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading flight_model (0.64 MBs): 100%|â–ˆ| 641715/641715 [00:00<00:00, 3226118.9\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-08-31T02:14:09.691301+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2022-08-31T02:14:09.691301+00:00\",\n",
      "    \"last_modified_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/models/fight_delay_model/versions/1\",\n",
      "  \"name\": \"fight_delay_model\",\n",
      "  \"path\": \"azureml://subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/workspaces/ws01/datastores/workspaceblobstore/paths/LocalUpload/263238d665167a65d872a835a7289865/flight_model\",\n",
      "  \"properties\": {},\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"custom_model\",\n",
      "  \"version\": \"1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml model create --name fight_delay_model \\\n",
    "  --version 1 \\\n",
    "  --path ./flight_model \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AML environment for Spark ML serving\n",
    "\n",
    "Next create AML environment for Spark ML serving.\n",
    "\n",
    "In this example, the image is built from AML minimal inferencing image (```mcr.microsoft.com/azureml/minimal-ubuntu20.04-py38-cpu-inference:latest```).<br>\n",
    "Apache Spark and pyspark is then installed and configured.\n",
    "\n",
    "The following ```azureml-defaults``` is needed for Azure ML inferencing by entry script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "context_folder = './docker-context-sparkml'\n",
    "os.makedirs(context_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing docker-context-sparkml/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker-context-sparkml/Dockerfile\n",
    "FROM mcr.microsoft.com/azureml/minimal-ubuntu20.04-py38-cpu-inference:latest\n",
    "\n",
    "USER root:root\n",
    "\n",
    "# Install Java\n",
    "RUN mkdir -p /usr/share/man/man1\n",
    "RUN apt-get update -y && \\\n",
    "    apt-get install -y openjdk-8-jdk\n",
    "ENV JAVA_HOME='/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "\n",
    "# Install Apache Spark\n",
    "RUN wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz && \\\n",
    "   tar xzf spark-3.1.2-bin-hadoop3.2.tgz -C /opt && \\\n",
    "   mv /opt/spark-3.1.2-bin-hadoop3.2 /opt/spark && \\\n",
    "   rm spark-3.1.2-bin-hadoop3.2.tgz\n",
    "ENV SPARK_HOME=/opt/spark\n",
    "ENV PYSPARK_PYTHON=python\n",
    "ENV PYTHONPATH=$PYTHONPATH:$SPARK_HOME/python\n",
    "\n",
    "# Install additional packages\n",
    "WORKDIR /\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt && rm requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing docker-context-sparkml/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker-context-sparkml/requirements.txt\n",
    "azureml-defaults\n",
    "numpy\n",
    "pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register new image as AML environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing env_sparkml_serving.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile env_sparkml_serving.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json\n",
    "name: sparkml-serving-env\n",
    "build:\n",
    "  path: docker-context-sparkml\n",
    "description: environment for SparkML serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading docker-context-sparkml (0.0 MBs): 100%|â–ˆ| 773/773 [00:00<00:00, 22976.\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"build\": {\n",
      "    \"dockerfile_path\": \"Dockerfile\",\n",
      "    \"path\": \"https://ws019192117290.blob.core.windows.net/azureml-blobstore-bdaba7c0-9940-43e5-a272-86b92d91b7de/LocalUpload/fbd5c3deea08489d938b69b1ce6e49b9/docker-context-sparkml/\"\n",
      "  },\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-08-31T02:14:40.661368+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2022-08-31T02:14:40.661368+00:00\",\n",
      "    \"last_modified_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"environment for SparkML serving\",\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/environments/sparkml-serving-env/versions/1\",\n",
      "  \"name\": \"sparkml-serving-env\",\n",
      "  \"os_type\": \"linux\",\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"tags\": {},\n",
      "  \"version\": \"1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml environment create --file env_sparkml_serving.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Inference Script\n",
    "\n",
    "Create the following inferencing code which will be deployed with inference images.<br>\n",
    "The following script is saved as ```./script/inference.py```.\n",
    "\n",
    "> Note : To use additional packages, specify ```config()``` in builder creation.<br>\n",
    "> For instance, when you use Azure storage, you can add package configuration as follows. (See [here](https://tsmatz.wordpress.com/2020/12/08/apache-spark-on-azure-kubernetes-service-aks/) for details.)\n",
    "> ```\n",
    "> spark = (SparkSession.builder\\\n",
    ">     .appName(\"flight_delay_serving\")\\\n",
    ">     .config(\"spark.jars.packages\",\n",
    ">         \"org.apache.hadoop:hadoop-azure:3.2.0\")\n",
    ">     .config(\"spark.jars.packages\",\n",
    ">         \"com.microsoft.azure:azure-storage:8.6.3\")\n",
    ">     .getOrCreate())\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = \"./script\"\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/inference.py\n",
    "import os\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "def init():\n",
    "    global spark\n",
    "    global loaded_model\n",
    "    spark = SparkSession.builder.appName(\"flight_delay_serving\").getOrCreate()\n",
    "    model_path = os.path.join(\n",
    "        os.getenv(\"AZUREML_MODEL_DIR\"),\n",
    "        \"flight_model\"\n",
    "    )\n",
    "    loaded_model = PipelineModel.load(model_path)\n",
    " \n",
    "def run(raw_data):\n",
    "    try:\n",
    "        input_list = json.loads(raw_data)[\"data\"]\n",
    "        sc = spark.sparkContext\n",
    "        input_rdd = sc.parallelize(input_list)\n",
    "        input_df = input_rdd.toDF()\n",
    "        pred_df = loaded_model.transform(input_df)\n",
    "        pred_list = pred_df.collect()\n",
    "        pred_array = [int(x[\"prediction\"]) for x in pred_list]\n",
    "        return pred_array\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return \"Internal Exception : \" + result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a managed endpoint\n",
    "\n",
    "Now create a managed endpoint. **Fill the following endpoint name**, which must be unique in DNS.\n",
    "\n",
    "Afterwards, we will deploy inferencing container image on this endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing managed_endpoint.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile managed_endpoint.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineEndpoint.schema.json\n",
    "name: {FILL_UNIQUE_ENDPOINT_NAME}\n",
    "auth_mode: key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"auth_mode\": \"key\",\n",
      "  \"id\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/onlineEndpoints/sparkml-test01\",\n",
      "  \"identity\": {\n",
      "    \"principal_id\": \"4b5b1518-1046-4e06-aa12-bf738c4b21dd\",\n",
      "    \"tenant_id\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "    \"type\": \"system_assigned\"\n",
      "  },\n",
      "  \"kind\": \"Managed\",\n",
      "  \"location\": \"eastus\",\n",
      "  \"mirror_traffic\": {},\n",
      "  \"name\": \"sparkml-test01\",\n",
      "  \"properties\": {\n",
      "    \"AzureAsyncOperationUri\": \"https://management.azure.com/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oe:bdaba7c0-9940-43e5-a272-86b92d91b7de:b235a268-79d1-46d7-827e-06e1da806fd9?api-version=2022-02-01-preview\",\n",
      "    \"azureml.onlineendpointid\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/aml-rg/providers/microsoft.machinelearningservices/workspaces/ws01/onlineendpoints/sparkml-test01\"\n",
      "  },\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"public_network_access\": \"enabled\",\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"scoring_uri\": \"https://sparkml-test01.eastus.inference.ml.azure.com/score\",\n",
      "  \"swagger_uri\": \"https://sparkml-test01.eastus.inference.ml.azure.com/swagger.json\",\n",
      "  \"tags\": {},\n",
      "  \"traffic\": {}\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint create --file managed_endpoint.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy inferencing for Spark ML serving\n",
    "\n",
    "Now we deploy inferencing image on this endpoint.\n",
    "\n",
    "In this deployment, we use custom environment, in which Apache Spark is installed and configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing managed_deployment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile managed_deployment.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json\n",
    "name: sparkml-deployment-v1\n",
    "endpoint_name: {FILL_UNIQUE_ENDPOINT_NAME}\n",
    "model: azureml:fight_delay_model@latest\n",
    "code_configuration:\n",
    "  code: ./script\n",
    "  scoring_script: inference.py\n",
    "environment: azureml:sparkml-serving-env@latest\n",
    "instance_type: Standard_DS3_v2\n",
    "instance_count: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All traffic will be set to deployment sparkml-deployment-v1 once it has been provisioned.\n",
      "If you interrupt this command or it times out while waiting for the provisioning, you can try to set all the traffic to this deployment later once its has been provisioned.\n",
      "Check: endpoint sparkml-test01 exists\n",
      "\u001b[32mUploading script (0.0 MBs): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 851/851 [00:00<00:00, 82012.61it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "Creating/updating online deployment sparkml-deployment-v1 ..........................................................................................Done (7m 56s)\n",
      "{\n",
      "  \"app_insights_enabled\": false,\n",
      "  \"code_configuration\": {\n",
      "    \"code\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/codes/ff3c3f96-fe3c-43be-9ea4-be9713038ae0/versions/1\",\n",
      "    \"scoring_script\": \"inference.py\"\n",
      "  },\n",
      "  \"endpoint_name\": \"sparkml-test01\",\n",
      "  \"environment\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/environments/sparkml-serving-env/versions/1\",\n",
      "  \"environment_variables\": {},\n",
      "  \"instance_count\": 1,\n",
      "  \"instance_type\": \"Standard_DS3_v2\",\n",
      "  \"model\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/models/fight_delay_model/versions/1\",\n",
      "  \"name\": \"sparkml-deployment-v1\",\n",
      "  \"properties\": {},\n",
      "  \"tags\": {},\n",
      "  \"type\": \"managed\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-deployment create --file managed_deployment.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --all-traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get endpoint url and key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deployment has completed, get endpoint url by the following command. (**Fill the following endpoint name**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"{FILL_UNIQUE_ENDPOINT_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"https://sparkml-test01.eastus.inference.ml.azure.com/score\"\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint show \\\n",
    "  --name $endpoint_name \\\n",
    "  --query scoring_uri \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get authorization key for this endpoint by the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"primaryKey\": \"dcSSJx9Oc6NDlkQCN3BV3sWDQQtOKg3n\",\r\n",
      "  \"secondaryKey\": \"BxyoTwj0wA1OmbOmDWXogXbgrwL9Z1rV\"\r\n",
      "}\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint get-credentials \\\n",
    "  --name $endpoint_name \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now predict flight delay with this endpoint as follows. (Call online inferencing.)\n",
    "\n",
    "In the following example, the predicted results of 2 rows are both ```0``` (which means \"not delayed\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = \"{FILL_ENDPOINT_URL}\"\n",
    "# Example : endpoint_url = \"https://sparkml-test01.eastus.inference.ml.azure.com/score\"\n",
    "authorization_key = \"{FILL_AUTHORIZATION_KEY}\"\n",
    "# Example : authorization_key = \"dcSSJx9Oc6NDlkQCN3BV3sWDQQtOKg3n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted :  [0, 0]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\":\"application/json\",\n",
    "    \"Authorization\":(\"Bearer \" + authorization_key),\n",
    "}\n",
    "input_data = \"\"\"\n",
    "{\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"MONTH\": 1,\n",
    "      \"DAY_OF_WEEK\": 1,\n",
    "      \"UNIQUE_CARRIER\": \"AA\",\n",
    "      \"ORIGIN\": \"ABQ\",\n",
    "      \"DEST\": \"DFW\",\n",
    "      \"CRS_DEP_TIME\": 9,\n",
    "      \"CRS_ARR_TIME\": 12,\n",
    "      \"RelativeHumidityOrigin\": 23.0,\n",
    "      \"AltimeterOrigin\": 30.55,\n",
    "      \"DryBulbCelsiusOrigin\": 9.4,\n",
    "      \"WindSpeedOrigin\": 3.0,\n",
    "      \"VisibilityOrigin\": 10.0,\n",
    "      \"DewPointCelsiusOrigin\": -10.6,\n",
    "      \"RelativeHumidityDest\": 35.0,\n",
    "      \"AltimeterDest\": 30.6,\n",
    "      \"DryBulbCelsiusDest\": 7.2,\n",
    "      \"WindSpeedDest\": 7.0,\n",
    "      \"VisibilityDest\": 10.0,\n",
    "      \"DewPointCelsiusDest\": -7.2\n",
    "    },\n",
    "    {\n",
    "      \"MONTH\": 1,\n",
    "      \"DAY_OF_WEEK\": 1,\n",
    "      \"UNIQUE_CARRIER\": \"AA\",\n",
    "      \"ORIGIN\": \"BNA\",\n",
    "      \"DEST\": \"DFW\",\n",
    "      \"CRS_DEP_TIME\": 12,\n",
    "      \"CRS_ARR_TIME\": 15,\n",
    "      \"RelativeHumidityOrigin\": 78.5,\n",
    "      \"AltimeterOrigin\": 30.05,\n",
    "      \"DryBulbCelsiusOrigin\": 10.8,\n",
    "      \"WindSpeedOrigin\": 1.5,\n",
    "      \"VisibilityOrigin\": 8.0,\n",
    "      \"DewPointCelsiusOrigin\": 7.1,\n",
    "      \"RelativeHumidityDest\": 86.0,\n",
    "      \"AltimeterDest\": 29.86,\n",
    "      \"DryBulbCelsiusDest\": 9.4,\n",
    "      \"WindSpeedDest\": 18.0,\n",
    "      \"VisibilityDest\": 6.0,\n",
    "      \"DewPointCelsiusDest\": 7.2\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "http_res = requests.post(\n",
    "  endpoint_url,\n",
    "  input_data,\n",
    "  headers = headers)\n",
    "print(\"Predicted : \", http_res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Remove endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml online-endpoint delete \\\n",
    "  --name $endpoint_name \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
