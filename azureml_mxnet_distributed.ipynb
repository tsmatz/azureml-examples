{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MXNet Distributed Training (MNIST Sample) in Azure Machine Learning\n",
    "\n",
    "To run this notebook,\n",
    "\n",
    "1. Create new \"Machine Learning\" resource in [Azure Portal](https://portal.azure.com/).\n",
    "2. Install Azure Machine Learning SDK (core package) as follows\n",
    "\n",
    "```\n",
    "pip install azureml-core\n",
    "```\n",
    "\n",
    "See \"[MXNet Distributed Training Example for Azure ML service](https://tsmatz.wordpress.com/2019/01/17/azure-machine-learning-service-custom-amlcompute-and-runconfig-for-mxnet-distributed-training/)\" for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create script for MXNet distributed training (mnist_distributed.py)\n",
    "\n",
    "Save a script file (mnist_distributed.py) for MXNet distributed training.\n",
    "\n",
    "> Note : Use commented lines on your debugging in local with 1 CPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/mnist_distributed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/mnist_distributed.py\n",
    "import os, random\n",
    "import mxnet as mx\n",
    "from mxnet import kv, gluon, autograd, nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "store = kv.create('dist')\n",
    "\n",
    "gpus_per_machine = 1\n",
    "batch_size_per_gpu = 64\n",
    "batch_size = batch_size_per_gpu * gpus_per_machine\n",
    "num_epochs = 5\n",
    "\n",
    "ctx = [mx.gpu(i) for i in range(gpus_per_machine)]\n",
    "# ctx = mx.cpu(0)\n",
    "\n",
    "class SplitSampler(gluon.data.sampler.Sampler):\n",
    "    \"\"\"\n",
    "    length: Number of examples in the dataset\n",
    "    num_parts: Partition the data into multiple parts\n",
    "    part_index: The index of the part to read from\n",
    "    \"\"\"\n",
    "    def __init__(self, length, num_parts, part_index):\n",
    "        self.part_len = length // num_parts\n",
    "        self.start = self.part_len * part_index\n",
    "        self.end = self.start + self.part_len\n",
    "    def __iter__(self):\n",
    "        indices = list(range(self.start, self.end))\n",
    "        random.shuffle(indices)\n",
    "        return iter(indices)\n",
    "    def __len__(self):\n",
    "        return self.part_len\n",
    "\n",
    "mx.random.seed(42)\n",
    "def data_xform(data):\n",
    "    \"\"\"Move channel axis to the beginning, cast to float32, and normalize to [0, 1]\"\"\"\n",
    "    return nd.moveaxis(data, 2, 0).astype('float32') / 255\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.MNIST(train=True).transform_first(data_xform),\n",
    "    batch_size=batch_size,\n",
    "    sampler=SplitSampler(59904, store.num_workers, store.rank))\n",
    "test_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.MNIST(train=False).transform_first(data_xform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "# train_data = gluon.data.DataLoader(\n",
    "#     gluon.data.vision.MNIST(train=True, root='./data').transform_first(data_xform),\n",
    "#     batch_size=batch_size)\n",
    "# test_data = gluon.data.DataLoader(\n",
    "#     gluon.data.vision.MNIST(train=False, root='./data').transform_first(data_xform),\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False)\n",
    "\n",
    "net = nn.HybridSequential(prefix='MLP_')\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(128, activation='relu'),\n",
    "        nn.Dense(64, activation='relu'),\n",
    "        nn.Dense(10, activation=None)\n",
    "    )\n",
    "\n",
    "net.hybridize()\n",
    "\n",
    "net.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "\n",
    "loss_function = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "trainer = gluon.Trainer(\n",
    "    params=net.collect_params(),\n",
    "    optimizer='sgd',\n",
    "    optimizer_params={'learning_rate': 0.07},\n",
    "    kvstore=store)\n",
    "# trainer = gluon.Trainer(\n",
    "#     params=net.collect_params(),\n",
    "#     optimizer='sgd',\n",
    "#     optimizer_params={'learning_rate': 0.07},\n",
    "# )\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \"\"\" Train ! \"\"\"\n",
    "    for batch in train_data:\n",
    "        inputs = gluon.utils.split_and_load(batch[0], ctx)\n",
    "        labels = gluon.utils.split_and_load(batch[1], ctx)\n",
    "        # inputs = batch[0].as_in_context(ctx)\n",
    "        # labels = batch[1].as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            loss = [loss_function(net(X), Y) for X, Y in zip(inputs, labels)]\n",
    "            # loss = loss_function(net(inputs), labels)\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "        # loss.backward()\n",
    "        trainer.step(batch_size=batch[0].shape[0])\n",
    "    \"\"\" Evaluate and Output ! \"\"\"\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, (test_input, test_label) in enumerate(test_data):\n",
    "        test_input = test_input.as_in_context(ctx[0])\n",
    "        test_label = test_label.as_in_context(ctx[0])\n",
    "        # test_input = test_input.as_in_context(ctx)\n",
    "        # test_label = test_label.as_in_context(ctx)\n",
    "        test_output = net(test_input)\n",
    "        test_pred = nd.argmax(test_output, axis=1)\n",
    "        metric.update(preds=test_pred, labels=test_label)\n",
    "    print('Epoch %d: Accuracy %f' % (epoch, metric.get()[1]))\n",
    "\n",
    "\"\"\" Save Model (both architecture and parameters) \"\"\"\n",
    "if store.rank == 0:\n",
    "    os.makedirs('./outputs', exist_ok=True)\n",
    "    net.export('./outputs/test', epoch=1)\n",
    "# os.makedirs('./outputs', exist_ok=True)\n",
    "# net.export('./outputs/test', epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create script for entry (start_mx_role.py)\n",
    "\n",
    "Create an entry script for starting each roles in MXNet distributed training.<br>\n",
    "Here we run 4 nodes with the following roles.\n",
    "\n",
    "- Rank 0 : Scheduler\n",
    "- Rank 1 : Parameter Server\n",
    "- Rank 2 : Worker\n",
    "- Rank 3 : Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/start_mx_role.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/start_mx_role.py\n",
    "import argparse\n",
    "import os\n",
    "from mpi4py import MPI\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--num_workers',\n",
    "    type=int,\n",
    "    default=0,\n",
    "    help='Specifies how many worker roles')\n",
    "parser.add_argument(\n",
    "    '--num_servers',\n",
    "    type=int,\n",
    "    default=0,\n",
    "    help='Specifies how many server roles')\n",
    "parser.add_argument(\n",
    "    '--scheduler_host',\n",
    "    type=str,\n",
    "    default='10.0.0.4',\n",
    "    help='Specifies the IP of the scheduler')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "#\n",
    "# See https://mxnet.incubator.apache.org/faq/distributed_training.html\n",
    "#\n",
    "\n",
    "mpi_comm = MPI.COMM_WORLD\n",
    "mpi_rank = mpi_comm.Get_rank()\n",
    "if mpi_rank == 0 :\n",
    "    # Rank 0 is scheduler\n",
    "    os.environ['DMLC_ROLE'] = 'scheduler'\n",
    "elif mpi_rank <= FLAGS.num_servers :\n",
    "    # Rank 1, ..., FLAGS.num_servers is server\n",
    "    os.environ['DMLC_ROLE'] = 'server'\n",
    "else :\n",
    "    # Others are all workers (The count of workers must equal to FLAGS.num_workers.)\n",
    "    os.environ['DMLC_ROLE'] = 'worker'\n",
    "os.environ['DMLC_PS_ROOT_URI'] = FLAGS.scheduler_host\n",
    "os.environ['DMLC_PS_ROOT_PORT'] = '9092'\n",
    "os.environ['DMLC_NUM_WORKER'] = str(FLAGS.num_workers)\n",
    "os.environ['DMLC_NUM_SERVER'] = str(FLAGS.num_servers)\n",
    "\n",
    "#\n",
    "# Run previous script !\n",
    "#\n",
    "import mnist_distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Connect to Azure Machine Learning (Create AML config)\n",
    "\n",
    "Connect to Azure Machine Learning (AML) workspace, which is a resource created above.<br>\n",
    "Please fill the following workspace name, subscription id, and resource group name. (You can get these values on AML resource blade in Azure Portal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code R448ZPH6H to authenticate.\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n",
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace(\n",
    "  workspace_name = \"{AML WORKSPACE NAME}\",\n",
    "  subscription_id = \"{SUBSCRIPTION ID}\",\n",
    "  resource_group = \"{RESOURCE GROUP NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create cluster (multiple nodes)\n",
    "\n",
    "Create a remote cluster with 4 node's GPU VMs - scheduler, parameter server, worker0, and worker1.\n",
    "\n",
    "For running GPU cluster in Machine Learning, **please check as follows**.\n",
    "\n",
    "- You should have quota for some dedicated ML GPU cluster in your Azure subscription. If you don't have, please request quota in Azure Portal.\n",
    "- Please fill the following ```vm_size``` and ```location``` for GPU cluster which you can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new.\n",
      "InProgress......\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded..........................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    " \n",
    "# Create AML compute (or Get existing one)\n",
    "# (Total 4 : scheduler, server, worker1, worker2)\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name='cluster01')\n",
    "    print('found existing:', compute_target.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='Standard_NC4as_T4_v3',\n",
    "        min_nodes=4,\n",
    "        max_nodes=4,\n",
    "        location=\"eastus\")\n",
    "    compute_target = ComputeTarget.create(ws, 'cluster01', compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate config for run\n",
    "\n",
    "Generate a script run configuration in AML.<br>\n",
    "Here we use custom container image, in which Open MPI is installed and configured. (See [here](https://tsmatz.wordpress.com/2019/01/17/azure-machine-learning-service-custom-amlcompute-and-runconfig-for-mxnet-distributed-training/) for details.)\n",
    "\n",
    "With ```$AZ_BATCH_MASTER_NODE```, it's getting master node's IP, such like \"10.0.0.4\". (Or use ```$AZ_BATCHAI_MPI_MASTER_NODE```.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core import Run, ScriptRunConfig\n",
    "from azureml.core.runconfig import DockerConfiguration, MpiConfiguration\n",
    "\n",
    "# create environment\n",
    "env = Environment('test-mxnet-gpu-env')\n",
    "conda_dep = CondaDependencies.create()\n",
    "conda_dep.add_pip_package('mxnet-cu90');\n",
    "conda_dep.add_pip_package('mpi4py');\n",
    "env.python.conda_dependencies = conda_dep\n",
    "env.docker.base_image = 'tsmatz/azureml-openmpi:0.1.0-gpu'\n",
    "\n",
    "# register environment to re-use later\n",
    "env.register(workspace=ws)\n",
    "## # speed up by using the existing environment\n",
    "## env = Environment.get(ws, name='test-mxnet-gpu-env')\n",
    "\n",
    "# create script run config\n",
    "src = ScriptRunConfig(\n",
    "    source_directory='./script',\n",
    "    script='start_mx_role.py',\n",
    "    arguments=[\n",
    "        '--num_workers', 2,\n",
    "        '--num_servers', 1,\n",
    "        '--scheduler_host', '`cut -d \":\" -f 1 <<< $AZ_BATCH_MASTER_NODE`'], \n",
    "    compute_target=compute_target,\n",
    "    environment=env,\n",
    "    docker_runtime_config=DockerConfiguration(use_docker=True),\n",
    "    distributed_job_config=MpiConfiguration(process_count_per_node=1, node_count=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: mnist_mxnet_distributed_1626666873_c49459f4\n",
      "Web View: https://ml.azure.com/runs/mnist_mxnet_distributed_1626666873_c49459f4?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/TEST20210719/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2021-07-19T03:54:53Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/mnist_mxnet_distributed_1626666873_c49459f4/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/mnist_mxnet_distributed_1626666873_c49459f4/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=311957 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/mnist_mxnet_distributed_1626666873_c49459f4/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-07-19T03:54:53Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/mnist_mxnet_distributed_1626666873_c49459f4/mounts/workspaceblobstore\n",
      "2021-07-19T03:54:53Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-07-19T03:54:53Z Starting output-watcher...\n",
      "2021-07-19T03:54:53Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_1fbeb284bbd5dd46e0c22d66c9803dc3\n",
      "Digest: sha256:3a00d0316cd0e3552ef6b991524f738df179a5b848021e4047d07a6424ccaee5\n",
      "Status: Image is up to date for b76d1e937e90483f8462237278c976d4.azurecr.io/azureml/azureml_1fbeb284bbd5dd46e0c22d66c9803dc3:latest\n",
      "b76d1e937e90483f8462237278c976d4.azurecr.io/azureml/azureml_1fbeb284bbd5dd46e0c22d66c9803dc3:latest\n",
      "2021-07-19T03:54:54Z Check if container mnist_mxnet_distributed_1626666873_c49459f4 already exist exited with 0, \n",
      "\n",
      "b0c0b20b4f2b2616e7d75e0b1f1254440b9ee95f7262d496ea550d3e8166c603\n",
      "2021-07-19T03:54:55Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to true \n",
      "2021-07-19T03:54:55Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-0f40ff13985812f4dd40283ae076b3f7-9de58931a9f16075-01 -sshRequired=true] \n",
      "2021/07/19 03:54:55 Starting App Insight Logger for task:  containerSetup\n",
      "2021/07/19 03:54:55 Version: 3.0.01655.0006 Branch: .SourceBranch Commit: b254912\n",
      "2021/07/19 03:54:55 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/07/19 03:54:55 Starting infiniband setup\n",
      "2021/07/19 03:54:55 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/07/19 03:54:55 Returning Python Version as 3.6\n",
      "2021-07-19T03:54:55Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/07/19 03:54:55 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/07/19 03:54:55 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/07/19 03:54:55 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-07-19T03:54:55Z Not setting up Infiniband in Container\n",
      "2021/07/19 03:54:55 Not setting up Infiniband in Container\n",
      "2021/07/19 03:54:55 Not setting up Infiniband in Container\n",
      "2021/07/19 03:54:55 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/07/19 03:54:55 Returning Python Version as 3.6\n",
      "2021/07/19 03:54:55 Starting setupPasswordLessSSH setup\n",
      "2021-07-19T03:54:55Z Setting up Passwordless SSH in Container\n",
      "2021/07/19 03:54:55 Setting up Passwordless SSH in Container\n",
      "2021/07/19 03:54:55 Setting up Passwordless SSH in Container\n",
      "(Reading database ... 11619 files and directories currently installed.)\n",
      "Preparing to unpack libkrb5support0_1.13.2+dfsg-5ubuntu2.1_amd64.deb ...\n",
      "Unpacking libkrb5support0:amd64 (1.13.2+dfsg-5ubuntu2.1) over (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Setting up libkrb5support0:amd64 (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "(Reading database ... 11619 files and directories currently installed.)\n",
      "Preparing to unpack libk5crypto3_1.13.2+dfsg-5ubuntu2.1_amd64.deb ...\n",
      "Unpacking libk5crypto3:amd64 (1.13.2+dfsg-5ubuntu2.1) over (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Setting up libk5crypto3:amd64 (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "(Reading database ... 11619 files and directories currently installed.)\n",
      "Preparing to unpack libkeyutils1_1.5.9-8ubuntu1_amd64.deb ...\n",
      "Unpacking libkeyutils1:amd64 (1.5.9-8ubuntu1) over (1.5.9-8ubuntu1) ...\n",
      "Setting up libkeyutils1:amd64 (1.5.9-8ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "(Reading database ... 11619 files and directories currently installed.)\n",
      "Preparing to unpack libkrb5-3_1.13.2+dfsg-5ubuntu2.1_amd64.deb ...\n",
      "Unpacking libkrb5-3:amd64 (1.13.2+dfsg-5ubuntu2.1) over (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Setting up libkrb5-3:amd64 (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "(Reading database ... 11619 files and directories currently installed.)\n",
      "Preparing to unpack libgssapi-krb5-2_1.13.2+dfsg-5ubuntu2.1_amd64.deb ...\n",
      "Unpacking libgssapi-krb5-2:amd64 (1.13.2+dfsg-5ubuntu2.1) over (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Setting up libgssapi-krb5-2:amd64 (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "(Reading database ... 11619 files and directories currently installed.)\n",
      "Preparing to unpack libssl1.0.0_1.0.2g-1ubuntu4.15_amd64.deb ...\n",
      "Unpacking libssl1.0.0:amd64 (1.0.2g-1ubuntu4.15) over (1.0.2g-1ubuntu4.15) ...\n",
      "Setting up libssl1.0.0:amd64 (1.0.2g-1ubuntu4.15) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "dpkg: warning: downgrading multiarch-support from 2.23-0ubuntu11 to 2.23-0ubuntu10\n",
      "(Reading database ... 11619 files and directories currently installed.)\n",
      "Preparing to unpack multiarch-support_2.23-0ubuntu10_amd64.deb ...\n",
      "Unpacking multiarch-support (2.23-0ubuntu10) over (2.23-0ubuntu11) ...\n",
      "Setting up multiarch-support (2.23-0ubuntu10) ...\n",
      "Selecting previously unselected package libwrap0:amd64.\n",
      "(Reading database ... 11619 files and directories currently installed.)\n",
      "Preparing to unpack libwrap0_7.6.q-25_amd64.deb ...\n",
      "Unpacking libwrap0:amd64 (7.6.q-25) ...\n",
      "Setting up libwrap0:amd64 (7.6.q-25) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "Selecting previously unselected package libbsd0:amd64.\n",
      "(Reading database ... 11630 files and directories currently installed.)\n",
      "Preparing to unpack libbsd0_0.8.2-1_amd64.deb ...\n",
      "Unpacking libbsd0:amd64 (0.8.2-1) ...\n",
      "Setting up libbsd0:amd64 (0.8.2-1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "Selecting previously unselected package libedit2:amd64.\n",
      "(Reading database ... 11635 files and directories currently installed.)\n",
      "Preparing to unpack libedit2_3.1-20150325-1ubuntu2_amd64.deb ...\n",
      "Unpacking libedit2:amd64 (3.1-20150325-1ubuntu2) ...\n",
      "Setting up libedit2:amd64 (3.1-20150325-1ubuntu2) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "Selecting previously unselected package openssh-client.\n",
      "(Reading database ... 11642 files and directories currently installed.)\n",
      "Preparing to unpack openssh-client_7.2p2-4ubuntu2.8_amd64.deb ...\n",
      "Unpacking openssh-client (1:7.2p2-4ubuntu2.8) ...\n",
      "Setting up openssh-client (1:7.2p2-4ubuntu2.8) ...\n",
      "Selecting previously unselected package openssh-sftp-server.\n",
      "(Reading database ... 11687 files and directories currently installed.)\n",
      "Preparing to unpack openssh-sftp-server_7.2p2-4ubuntu2.8_amd64.deb ...\n",
      "Unpacking openssh-sftp-server (1:7.2p2-4ubuntu2.8) ...\n",
      "Setting up openssh-sftp-server (1:7.2p2-4ubuntu2.8) ...\n",
      "Selecting previously unselected package openssh-server.\n",
      "(Reading database ... 11691 files and directories currently installed.)\n",
      "Preparing to unpack openssh-server_7.2p2-4ubuntu2.8_amd64.deb ...\n",
      "Unpacking openssh-server (1:7.2p2-4ubuntu2.8) ...\n",
      "Setting up openssh-server (1:7.2p2-4ubuntu2.8) ...\n",
      "Creating SSH2 RSA key; this may take some time ...ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "2048 SHA256:rGwJWVhoHnjClcW/Xeufuv5E3cFtb6zevNI7FclAJOg root@2f8380b4420e4dbd862eaa59faf6751b000004 (RSA)\n",
      "Creating SSH2 DSA key; this may take some time ...ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "1024 SHA256:hmPJ9dPmf3ur22lV7X0lFZVDYJlUo2A0wBLsryjxOUc root@2f8380b4420e4dbd862eaa59faf6751b000004 (DSA)\n",
      "Creating SSH2 ECDSA key; this may take some time ...ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "256 SHA256:f127nwm3Zr9rRzuJoQt6cSgwsevHLyarYKQ4E7ufubU root@2f8380b4420e4dbd862eaa59faf6751b000004 (ECDSA)\n",
      "Creating SSH2 ED25519 key; this may take some time ...ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "256 SHA256:up/85l/xHq44ozM8XYpoNmXIv7/5pkLGWOH8mbtHrro root@2f8380b4420e4dbd862eaa59faf6751b000004 (ED25519)\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Processing triggers for systemd (229-4ubuntu21.22) ...\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_397dc57a34dd30142543d37f8a4aaab5/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "2021/07/19 03:54:58 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/07/19 03:54:58 App Insight Client has already been closed\n",
      "2021/07/19 03:54:58 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-07-19T03:54:58Z Starting docker container succeeded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/70_driver_log_0.txt\n",
      "==========================================\n",
      "\n",
      "[2021-07-19T03:55:02.154394] Entering context manager injector.\n",
      "[2021-07-19T03:55:02.617227] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['start_mx_role.py', '--num_workers', '2', '--num_servers', '1', '--scheduler_host', '10.0.0.5'])\n",
      "This is an MPI job. Rank:0\n",
      "Script type = None\n",
      "[2021-07-19T03:55:02.620903] Entering Run History Context Manager.\n",
      "[2021-07-19T03:55:03.280680] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/mnist_mxnet_distributed_1626666873_c49459f4/wd/azureml/mnist_mxnet_distributed_1626666873_c49459f4\n",
      "[2021-07-19T03:55:03.280921] Preparing to call script [start_mx_role.py] with arguments:['--num_workers', '2', '--num_servers', '1', '--scheduler_host', '10.0.0.5']\n",
      "[2021-07-19T03:55:03.281007] After variable expansion, calling script [start_mx_role.py] with arguments:['--num_workers', '2', '--num_servers', '1', '--scheduler_host', '10.0.0.5']\n",
      "\n",
      "[03:55:04] src/base.cc:51: Upgrade advisory: this mxnet has been built against cuda library version 9000, which is older than the oldest version tested by CI (10000).  Set MXNET_CUDA_LIB_CHECKING=0 to quiet this warning.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-07-19T03:56:12.574486] Entering job release\n",
      "[2021-07-19T03:56:13.613341] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-07-19T03:56:13.613385] job release stage : copy_batchai_cached_logs completed...\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: mnist_mxnet_distributed_1626666873_c49459f4\n",
      "Web View: https://ml.azure.com/runs/mnist_mxnet_distributed_1626666873_c49459f4?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/TEST20210719/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'mnist_mxnet_distributed_1626666873_c49459f4',\n",
       " 'target': 'cluster01',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-07-19T03:54:48.930013Z',\n",
       " 'endTimeUtc': '2021-07-19T03:56:25.697589Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'a656e20f-3a58-4752-88ba-585ad7e71ac1',\n",
       "  'azureml.git.repository_uri': 'https://github.com/tsmatz/azureml-samples.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/tsmatz/azureml-samples.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '2cfb88db961caedb534362729bc36ba0189a4380',\n",
       "  'mlflow.source.git.commit': '2cfb88db961caedb534362729bc36ba0189a4380',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json',\n",
       "  'azureml.RuntimeType': 'Hosttools'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'start_mx_role.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--num_workers',\n",
       "   '2',\n",
       "   '--num_servers',\n",
       "   '1',\n",
       "   '--scheduler_host',\n",
       "   '`cut -d \":\" -f 1 <<< $AZ_BATCH_MASTER_NODE`'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'Mpi',\n",
       "  'target': 'cluster01',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 4,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'test-mxnet-gpu-env',\n",
       "   'version': '1',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults~=1.32.0', 'mxnet-cu90', 'mpi4py']}],\n",
       "     'name': 'azureml_397dc57a34dd30142543d37f8a4aaab5'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'tsmatz/azureml-openmpi:0.1.0-gpu',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': None,\n",
       "   'slaTier': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/55_azureml-execution-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt?sv=2019-02-02&sr=b&sig=VGGmaZKwTa36ZGa4i0VYDfCsrEc2mndoK87iZK87cJ8%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_4f6aea116ce43cf7eec456d73564f080b26058c117e597f94b7545cc953cf93e_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/55_azureml-execution-tvmps_4f6aea116ce43cf7eec456d73564f080b26058c117e597f94b7545cc953cf93e_d.txt?sv=2019-02-02&sr=b&sig=iES2nY3Tj6TaRDEWVYOmEqWqBsH5CBM2WiHdMY8Hhp4%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_b6f63e9eb0f173c6ae1e249728ea934f5a022453bd47eaf1246b5528eca6deb8_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/55_azureml-execution-tvmps_b6f63e9eb0f173c6ae1e249728ea934f5a022453bd47eaf1246b5528eca6deb8_d.txt?sv=2019-02-02&sr=b&sig=axQ%2F2s9Ngo6EFtuSiP8bMRNxu6rsjBBrycxMzfs%2FDVE%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_ddb28de6ba3497cec85dbdfc2d44933be8933d6cde5411fbab69b055558f504b_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/55_azureml-execution-tvmps_ddb28de6ba3497cec85dbdfc2d44933be8933d6cde5411fbab69b055558f504b_d.txt?sv=2019-02-02&sr=b&sig=OYU%2Fdib5FZDzlhC46Ost85joqM0bjSxp9qg9lsedM%2B4%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/65_job_prep-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt?sv=2019-02-02&sr=b&sig=%2F%2B17Zm9zH7i%2F7ANIlvFP1gwNlsQ00oTFdtJMijwCOWw%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_4f6aea116ce43cf7eec456d73564f080b26058c117e597f94b7545cc953cf93e_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/65_job_prep-tvmps_4f6aea116ce43cf7eec456d73564f080b26058c117e597f94b7545cc953cf93e_d.txt?sv=2019-02-02&sr=b&sig=BdinU2Z0lBE%2BJwpO%2F1hqxqEWjcDAv5iOTRdvQxcG11k%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_b6f63e9eb0f173c6ae1e249728ea934f5a022453bd47eaf1246b5528eca6deb8_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/65_job_prep-tvmps_b6f63e9eb0f173c6ae1e249728ea934f5a022453bd47eaf1246b5528eca6deb8_d.txt?sv=2019-02-02&sr=b&sig=aOS%2FZzYJpGbLLzaxRVVpFw9m7R%2B1CLnnVELE46mWu%2Bo%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_ddb28de6ba3497cec85dbdfc2d44933be8933d6cde5411fbab69b055558f504b_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/65_job_prep-tvmps_ddb28de6ba3497cec85dbdfc2d44933be8933d6cde5411fbab69b055558f504b_d.txt?sv=2019-02-02&sr=b&sig=4QNivqohdZhQvQXKjNJiY1qq1%2Bk%2BEduivomyrovcPYg%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_0.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=Ea0x3P0zq8iVK3SCsnmiSTt37x9o9XWKA9mIYqnSmds%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_1.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=v2Ot%2BqKg%2BDuUHNZe8dnk%2B%2BpEi9yHVVHl5wRDQQt5m3w%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_2.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/70_driver_log_2.txt?sv=2019-02-02&sr=b&sig=JhU3wRYoATKNXm%2FERl7jb4dE%2FfQ9HGJA9YRHmtzna5I%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_3.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/70_driver_log_3.txt?sv=2019-02-02&sr=b&sig=GzhWsCjw6F3pj8ZNuWrYMA91FQuxiYcuzlBCRYz4lRw%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/70_mpi_log.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/70_mpi_log.txt?sv=2019-02-02&sr=b&sig=L4sh3aDiA%2FDBprKFLPkKLvQGTTpFE7mNfGHwi0DtB%2BA%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/75_job_post-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt?sv=2019-02-02&sr=b&sig=i3x2uWIomE6Qoi5IMaM9XjwfBW1sGxvn3stSmrmM2zs%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_4f6aea116ce43cf7eec456d73564f080b26058c117e597f94b7545cc953cf93e_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/75_job_post-tvmps_4f6aea116ce43cf7eec456d73564f080b26058c117e597f94b7545cc953cf93e_d.txt?sv=2019-02-02&sr=b&sig=2L8Zg67dazfEutbm6LsMIKtnPCEEemJhN9K0t%2FC9gt8%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_b6f63e9eb0f173c6ae1e249728ea934f5a022453bd47eaf1246b5528eca6deb8_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/75_job_post-tvmps_b6f63e9eb0f173c6ae1e249728ea934f5a022453bd47eaf1246b5528eca6deb8_d.txt?sv=2019-02-02&sr=b&sig=Hco3YNtBGkYnZ03mmNHUvXeNtqop3weVq9JLc7gx6Sc%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_ddb28de6ba3497cec85dbdfc2d44933be8933d6cde5411fbab69b055558f504b_d.txt': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/75_job_post-tvmps_ddb28de6ba3497cec85dbdfc2d44933be8933d6cde5411fbab69b055558f504b_d.txt?sv=2019-02-02&sr=b&sig=W3PqM%2FTwZN5t%2FaJ%2FZwtoWQeZO2LSiLr2K%2BF6g%2BkeYHA%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=bLSu%2FNsQ4MWBKlkc8vhlJcmekpZyO%2Bxr0pIuvTjp0Lo%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=YOvFfMqmnS1yoQBfmG10dtL2E5CWRaUzrmzkdUdS8Oo%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'logs/azureml/0_369_azureml.log': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/logs/azureml/0_369_azureml.log?sv=2019-02-02&sr=b&sig=sB0Nx63wE2%2FGOdaruY1t9lzqAuF3b8B1X3aD3VpdKlA%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'logs/azureml/1_364_azureml.log': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/logs/azureml/1_364_azureml.log?sv=2019-02-02&sr=b&sig=AoFriDaorddbp1j1GGUZK2h00clK2NMFeP1bEG0GDic%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'logs/azureml/2_362_azureml.log': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/logs/azureml/2_362_azureml.log?sv=2019-02-02&sr=b&sig=3vF5O8fnaHNPjiYC%2B6a29Iki9NuAo5nfHEZbINljDt0%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'logs/azureml/3_363_azureml.log': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/logs/azureml/3_363_azureml.log?sv=2019-02-02&sr=b&sig=qHnPYUBNFS9Fsb5Hcu3cZXDOi5iv%2F9YyoBIAE8i3nRE%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=pvJI0NWbWSpZQ0IJPFBqka%2FvqwgA52%2F0IE%2Fev1sKW2U%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://ws018805174418.blob.core.windows.net/azureml/ExperimentRun/dcid.mnist_mxnet_distributed_1626666873_c49459f4/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=7hbpnUO%2FsuZo3W9VoN04InfNlyB1RIGmDdnjOy889Z0%3D&st=2021-07-19T03%3A46%3A36Z&se=2021-07-19T11%3A56%3A36Z&sp=r'},\n",
       " 'submittedBy': 'Tsuyoshi Matsuzaki'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name='mnist_mxnet_distributed')\n",
    "run = exp.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. See the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the output results. These are all managed in Azure Machine Learning experiment's logging.<br>\n",
    "The \"```outputs```\" folder includes a generated model (both ```outputs/test-0001.params``` and ```outputs/test-symbol.json```) by MXNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/55_azureml-execution-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt',\n",
       " 'azureml-logs/55_azureml-execution-tvmps_4f6aea116ce43cf7eec456d73564f080b26058c117e597f94b7545cc953cf93e_d.txt',\n",
       " 'azureml-logs/55_azureml-execution-tvmps_b6f63e9eb0f173c6ae1e249728ea934f5a022453bd47eaf1246b5528eca6deb8_d.txt',\n",
       " 'azureml-logs/55_azureml-execution-tvmps_ddb28de6ba3497cec85dbdfc2d44933be8933d6cde5411fbab69b055558f504b_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_4f6aea116ce43cf7eec456d73564f080b26058c117e597f94b7545cc953cf93e_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_b6f63e9eb0f173c6ae1e249728ea934f5a022453bd47eaf1246b5528eca6deb8_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_ddb28de6ba3497cec85dbdfc2d44933be8933d6cde5411fbab69b055558f504b_d.txt',\n",
       " 'azureml-logs/70_driver_log_0.txt',\n",
       " 'azureml-logs/70_driver_log_1.txt',\n",
       " 'azureml-logs/70_driver_log_2.txt',\n",
       " 'azureml-logs/70_driver_log_3.txt',\n",
       " 'azureml-logs/70_mpi_log.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_21fb42f5e7a0d9d5743a41c31bda5cd6ef0e8bcd1a6672e91d3e9a44a3a79658_d.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_4f6aea116ce43cf7eec456d73564f080b26058c117e597f94b7545cc953cf93e_d.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_b6f63e9eb0f173c6ae1e249728ea934f5a022453bd47eaf1246b5528eca6deb8_d.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_ddb28de6ba3497cec85dbdfc2d44933be8933d6cde5411fbab69b055558f504b_d.txt',\n",
       " 'azureml-logs/process_info.json',\n",
       " 'azureml-logs/process_status.json',\n",
       " 'logs/azureml/0_369_azureml.log',\n",
       " 'logs/azureml/1_364_azureml.log',\n",
       " 'logs/azureml/2_362_azureml.log',\n",
       " 'logs/azureml/3_363_azureml.log',\n",
       " 'logs/azureml/job_prep_azureml.log',\n",
       " 'logs/azureml/job_release_azureml.log',\n",
       " 'outputs/test-0001.params',\n",
       " 'outputs/test-symbol.json']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see and download results (test-symbol.json, test-0001.params).\n",
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to see the validation results in workers (see above source code), you can download these logs on rank2 and rank3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.download_file(\n",
    "    name='azureml-logs/70_driver_log_2.txt',\n",
    "    output_file_path='remote_logs/70_driver_log_2.txt')\n",
    "run.download_file(\n",
    "    name='azureml-logs/70_driver_log_3.txt',\n",
    "    output_file_path='remote_logs/70_driver_log_3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> remote_logs/70_driver_log_2.txt <==\r\n",
      "Downloading /root/.mxnet/datasets/mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-labels-idx1-ubyte.gz...\r\n",
      "Downloading /root/.mxnet/datasets/mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-images-idx3-ubyte.gz...\r\n",
      "Downloading /root/.mxnet/datasets/mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-labels-idx1-ubyte.gz...\r\n",
      "Epoch 0: Accuracy 0.937700\r\n",
      "Epoch 1: Accuracy 0.955500\r\n",
      "Epoch 2: Accuracy 0.963900\r\n",
      "Epoch 3: Accuracy 0.968300\r\n",
      "Epoch 4: Accuracy 0.971400\r\n",
      "\r\n",
      "\r\n",
      "[2021-07-19T03:56:07.820678] The experiment completed successfully. Finalizing run...\r\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\r\n",
      "1 items cleaning up...\r\n",
      "Cleanup took 0.07885503768920898 seconds\r\n",
      "[2021-07-19T03:56:08.024354] Finished context manager injector.\r\n",
      "\r\n",
      "==> remote_logs/70_driver_log_3.txt <==\r\n",
      "Downloading /root/.mxnet/datasets/mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-labels-idx1-ubyte.gz...\r\n",
      "Downloading /root/.mxnet/datasets/mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-images-idx3-ubyte.gz...\r\n",
      "Downloading /root/.mxnet/datasets/mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-labels-idx1-ubyte.gz...\r\n",
      "Epoch 0: Accuracy 0.937700\r\n",
      "Epoch 1: Accuracy 0.955500\r\n",
      "Epoch 2: Accuracy 0.963900\r\n",
      "Epoch 3: Accuracy 0.968300\r\n",
      "Epoch 4: Accuracy 0.971400\r\n",
      "\r\n",
      "\r\n",
      "[2021-07-19T03:56:07.911487] The experiment completed successfully. Finalizing run...\r\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\r\n",
      "1 items cleaning up...\r\n",
      "Cleanup took 0.05979299545288086 seconds\r\n",
      "[2021-07-19T03:56:08.102646] Finished context manager injector.\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 15 remote_logs/70_driver_log_2.txt remote_logs/70_driver_log_3.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Remove cluster (Clean-up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cluster (nodes) in AML workspace\n",
    "mycompute = AmlCompute(workspace=ws, name='cluster01')\n",
    "mycompute.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
